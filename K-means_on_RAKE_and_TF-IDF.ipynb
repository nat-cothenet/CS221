{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CS221_11292018_0824 includes a RAKE class that applies RAKE on the input file\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "import collections\n",
    "import gzip\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "meta_data = []\n",
    "# meta_path= '/Users/srishti/Desktop/meta_Books.json.gz'\n",
    "meta_path= '/Users/srishti/Desktop/meta_Health_and_Personal_Care.json.gz'\n",
    "counter= 1\n",
    "\n",
    "\n",
    "for line in parse(meta_path):\n",
    "    meta_data.append(line)\n",
    "asin_title_map = collections.defaultdict(list)\n",
    "\n",
    "for i in meta_data:\n",
    "    if 'title' in i.keys():\n",
    "        asin_title_map[i['asin']] = i['title']\n",
    "    else:\n",
    "        asin_title_map[i['asin']] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B00CQ7SOQC Natural Vitality - Energy 28 Nutri Packs 15pk box\n",
      "B0047XXSV4 Prevail Specialty Briefs, 2X-Large (Case of 48 Briefs)\n",
      "B009HT2XBO 1/2&quot; + 5/8&quot; + 3/4&quot; Medical Stainless Ben Wa Ball Kegel Vaginal Tight Exerciser\n",
      "B001E7666A Aura Cacia Room and Body Mist, Sensual Cinnamon and Ylang Ylang, 4 Fluid Ounce\n",
      "B00BA3G7RQ Arctic Powder Super-flex Cold Pack with Magnetic Therapy, 2 Pack\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for i in asin_title_map.keys():\n",
    "    if counter <5:\n",
    "        print i+ \" \"+ asin_title_map[i]\n",
    "        counter+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_data_points_to_read= 10000 #Select number of data points to read\n",
    "counter= 1\n",
    "data=[]\n",
    "# path= '/Users/srishti/Desktop/reviews_Books_5.json'reviews_Health_and_Personal_Care_5\n",
    "path= '/Users/srishti/Desktop/reviews_Health_and_Personal_Care_5.json'\n",
    "with open(path) as f:\n",
    "    for line in f:\n",
    "#         if counter <number_of_data_points_to_read:\n",
    "        data.append(json.loads(line))\n",
    "        counter+=1\n",
    "#         else: \n",
    "#             break\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346355\n"
     ]
    }
   ],
   "source": [
    "print len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would recommend this for a travel magnifier for the occasional reading.I had read on another review about a magnifier having a problem with the light coming on. I did find that this one appeared to be DOA out of the box. But, after opening & shutting the viewer to turn on & off the light, the light began to come on. After several times of doing this, the light appears to be coming on all the time.It is small, but for taking it someplace & reading things like a menu in a dark corner of a restaurant, this is great.\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# path= '/Users/srishti/Google Drive/000_7th Quarter/CS221/Project/untouched_data/reviews_Automotive_5.json'\n",
    "# data = []\n",
    "# with open(path) as f:\n",
    "#     for line in f:\n",
    "#         data.append(json.loads(line))\n",
    "\n",
    "# d[1]\n",
    "# for j in data[1]:\n",
    "#     print j\n",
    "# print data[1]['reviewText']\n",
    "\n",
    "X=[] #reivews\n",
    "Y=[] #ratings\n",
    "\n",
    "for i in data:\n",
    "    X.append(i['reviewText'])\n",
    "    Y.append(i['overall'])\n",
    "\n",
    "print X[1]\n",
    "print Y[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin_dict = collections.defaultdict(list)\n",
    "for i in data:\n",
    "    X.append(i['reviewText'])\n",
    "    Y.append(i['overall'])\n",
    "    asin_dict[i['asin']].append(i['reviewText'])\n",
    "#     if i['overall'] >= 4:\n",
    "#         asin_dict[i['asin']+\"_pos\"].append(i['reviewText'])\n",
    "        \n",
    "#     else:\n",
    "#         asin_dict[i['asin']+\"_neg\"].append(i['reviewText'])\n",
    "\n",
    "# Merges the list of reviews for each asin_pos and asin_neg into a single string\n",
    "for j in asin_dict.keys():\n",
    "\tasin_dict[j] = \" \".join(asin_dict[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18534\n"
     ]
    }
   ],
   "source": [
    "print len(asin_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B000G6480G\n",
      "B0013J90AS\n",
      "B000EXS6D6\n",
      "B0032DP7Y6\n",
      "B004W4MNSM\n",
      "B006OC3JY2\n",
      "B006W9QIM2\n",
      "B0014UFVBI\n",
      "B00C1C23FU\n",
      "B000RQ2DMK\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in asin_dict.keys():\n",
    "    if count < 10:\n",
    "        print i\n",
    "        count+=1\n",
    "    else:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18534\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for i in asin_dict.keys():\n",
    "#     print i \n",
    "    if i in asin_title_map.keys():\n",
    "#         print i\n",
    "        counter +=1    \n",
    "print counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "embeddings_index = dict()\n",
    "f = open('/Users/srishti/Google Drive/000_7th Quarter/CS221/Project/untouched_data/glove.6B/glove.6B.50d.txt')\n",
    "for line in f:# first element of each line is the word and remaining elements are numerical represenation of each line \n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs# creates a dict of words and numerical representation of that word\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02648  ,  0.33737  ,  0.065667 , -0.11609  ,  0.41651  ,\n",
       "       -0.21142  , -0.69582  ,  0.2822   , -0.36077  , -0.13822  ,\n",
       "        0.012094 ,  0.086227 , -0.84638  ,  0.057195 ,  1.1582   ,\n",
       "        0.14703  , -0.0049197, -0.24899  , -0.96014  , -0.3038   ,\n",
       "        0.23972  ,  0.21058  ,  0.40608  ,  0.17789  ,  0.55253  ,\n",
       "       -1.6357   , -0.17784  , -0.45222  ,  0.45805  ,  0.14239  ,\n",
       "        3.7087   ,  0.40289  , -0.4083   , -0.29304  ,  0.030857 ,\n",
       "       -0.15361  ,  0.10607  ,  0.63397  ,  0.12397  , -0.25349  ,\n",
       "       -0.10344  ,  0.0069768, -0.17328  ,  0.35536  , -0.46369  ,\n",
       "        0.15285  ,  0.41475  , -0.3398   , -0.23043  ,  0.19069  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['dog']\n",
    "embeddings_index['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Implementation of Rapid Automatic Keyword Extraction algorithm.\n",
    "As described in the paper `Automatic keyword extraction from individual\n",
    "documents` by Stuart Rose, Dave Engel, Nick Cramer and Wendy Cowley.\n",
    "\"\"\"\n",
    "\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain, groupby, product\n",
    "\n",
    "import nltk\n",
    "from enum import Enum\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "\n",
    "class Metric(Enum):\n",
    "    \"\"\"Different metrics that can be used for ranking.\"\"\"\n",
    "\n",
    "    DEGREE_TO_FREQUENCY_RATIO = 0  # Uses d(w)/f(w) as the metric\n",
    "    WORD_DEGREE = 1  # Uses d(w) alone as the metric\n",
    "    WORD_FREQUENCY = 2  # Uses f(w) alone as the metric\n",
    "\n",
    "\n",
    "class Rake(object):\n",
    "    \"\"\"Rapid Automatic Keyword Extraction Algorithm.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        stopwords=None,\n",
    "        punctuations=None,\n",
    "        language=\"english\",\n",
    "        ranking_metric=Metric.DEGREE_TO_FREQUENCY_RATIO,\n",
    "        max_length=10000,\n",
    "        min_length=1,\n",
    "    ):\n",
    "        \"\"\"Constructor.\n",
    "        :param stopwords: List of Words to be ignored for keyword extraction.\n",
    "        :param punctuations: Punctuations to be ignored for keyword extraction.\n",
    "        :param language: Language to be used for stopwords\n",
    "        :param max_length: Maximum limit on the number of words in a phrase\n",
    "                           (Inclusive. Defaults to 100000)\n",
    "        :param min_length: Minimum limit on the number of words in a phrase\n",
    "                           (Inclusive. Defaults to 1)\n",
    "        \"\"\"\n",
    "        # By default use degree to frequency ratio as the metric.\n",
    "        if isinstance(ranking_metric, Metric):\n",
    "            self.metric = ranking_metric\n",
    "        else:\n",
    "            self.metric = Metric.DEGREE_TO_FREQUENCY_RATIO\n",
    "\n",
    "        # If stopwords not provided we use language stopwords by default.\n",
    "        self.stopwords = stopwords\n",
    "        if self.stopwords is None:\n",
    "            self.stopwords = nltk.corpus.stopwords.words(language)\n",
    "\n",
    "        # If punctuations are not provided we ignore all punctuation symbols.\n",
    "        self.punctuations = punctuations\n",
    "        if self.punctuations is None:\n",
    "            self.punctuations = string.punctuation\n",
    "\n",
    "        # All things which act as sentence breaks during keyword extraction.\n",
    "        self.to_ignore = set(chain(self.stopwords, self.punctuations))\n",
    "\n",
    "        # Assign min or max length to the attributes\n",
    "        self.min_length = min_length\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Stuff to be extracted from the provided text.\n",
    "        self.frequency_dist = None\n",
    "        self.degree = None\n",
    "        self.rank_list = None\n",
    "        self.ranked_phrases = None\n",
    "\n",
    "    def extract_keywords_from_text(self, text):\n",
    "        \"\"\"Method to extract keywords from the text provided.\n",
    "        :param text: Text to extract keywords from, provided as a string.\n",
    "        \"\"\"\n",
    "        sentences = nltk.tokenize.sent_tokenize(text)\n",
    "        self.extract_keywords_from_sentences(sentences)\n",
    "\n",
    "    def extract_keywords_from_sentences(self, sentences):\n",
    "        \"\"\"Method to extract keywords from the list of sentences provided.\n",
    "        :param sentences: Text to extraxt keywords from, provided as a list\n",
    "                          of strings, where each string is a sentence.\n",
    "        \"\"\"\n",
    "        phrase_list = self._generate_phrases(sentences)\n",
    "        self._build_frequency_dist(phrase_list)\n",
    "        self._build_word_co_occurance_graph(phrase_list)\n",
    "        self._build_ranklist(phrase_list)\n",
    "\n",
    "    def get_ranked_phrases(self):\n",
    "        \"\"\"Method to fetch ranked keyword strings.\n",
    "        :return: List of strings where each string represents an extracted\n",
    "                 keyword string.\n",
    "        \"\"\"\n",
    "        return self.ranked_phrases\n",
    "\n",
    "    def get_ranked_phrases_with_scores(self):\n",
    "        \"\"\"Method to fetch ranked keyword strings along with their scores.\n",
    "        :return: List of tuples where each tuple is formed of an extracted\n",
    "                 keyword string and its score. Ex: (5.68, 'Four Scoures')\n",
    "        \"\"\"\n",
    "        return self.rank_list\n",
    "\n",
    "    def get_word_frequency_distribution(self):\n",
    "        \"\"\"Method to fetch the word frequency distribution in the given text.\n",
    "        :return: Dictionary (defaultdict) of the format `word -> frequency`.\n",
    "        \"\"\"\n",
    "        return self.frequency_dist\n",
    "\n",
    "    def get_word_degrees(self):\n",
    "        \"\"\"Method to fetch the degree of words in the given text. Degree can be\n",
    "        defined as sum of co-occurances of the word with other words in the\n",
    "        given text.\n",
    "        :return: Dictionary (defaultdict) of the format `word -> degree`.\n",
    "        \"\"\"\n",
    "        return self.degree\n",
    "\n",
    "    def _build_frequency_dist(self, phrase_list):\n",
    "        \"\"\"Builds frequency distribution of the words in the given body of text.\n",
    "        :param phrase_list: List of List of strings where each sublist is a\n",
    "                            collection of words which form a contender phrase.\n",
    "        \"\"\"\n",
    "        self.frequency_dist = Counter(chain.from_iterable(phrase_list))\n",
    "\n",
    "    def _build_word_co_occurance_graph(self, phrase_list):\n",
    "        \"\"\"Builds the co-occurance graph of words in the given body of text to\n",
    "        compute degree of each word.\n",
    "        :param phrase_list: List of List of strings where each sublist is a\n",
    "                            collection of words which form a contender phrase.\n",
    "        \"\"\"\n",
    "        co_occurance_graph = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        for phrase in phrase_list:\n",
    "            # For each phrase in the phrase list, count co-occurances of the\n",
    "            # word with other words in the phrase.\n",
    "            #\n",
    "            # Note: Keep the co-occurances graph as is, to help facilitate its\n",
    "            # use in other creative ways if required later.\n",
    "            for (word, coword) in product(phrase, phrase):\n",
    "                co_occurance_graph[word][coword] += 1\n",
    "        self.degree = defaultdict(lambda: 0)\n",
    "        for key in co_occurance_graph:\n",
    "            self.degree[key] = sum(co_occurance_graph[key].values())\n",
    "\n",
    "    def _build_ranklist(self, phrase_list):\n",
    "        \"\"\"Method to rank each contender phrase using the formula\n",
    "              phrase_score = sum of scores of words in the phrase.\n",
    "              word_score = d(w)/f(w) where d is degree and f is frequency.\n",
    "        :param phrase_list: List of List of strings where each sublist is a\n",
    "                            collection of words which form a contender phrase.\n",
    "        \"\"\"\n",
    "        self.rank_list = []\n",
    "        for phrase in phrase_list:\n",
    "            rank = 0.0\n",
    "            for word in phrase:\n",
    "                if self.metric == Metric.DEGREE_TO_FREQUENCY_RATIO:\n",
    "                    rank += 1.0 * self.degree[word] / self.frequency_dist[word]\n",
    "                elif self.metric == Metric.WORD_DEGREE:\n",
    "                    rank += 1.0 * self.degree[word]\n",
    "                else:\n",
    "                    rank += 1.0 * self.frequency_dist[word]\n",
    "            self.rank_list.append((rank, \" \".join(phrase)))\n",
    "        self.rank_list.sort(reverse=True)\n",
    "        self.ranked_phrases = [ph[1] for ph in self.rank_list]\n",
    "\n",
    "    def _generate_phrases(self, sentences):\n",
    "        \"\"\"Method to generate contender phrases given the sentences of the text\n",
    "        document.\n",
    "        :param sentences: List of strings where each string represents a\n",
    "                          sentence which forms the text.\n",
    "        :return: Set of string tuples where each tuple is a collection\n",
    "                 of words forming a contender phrase.\n",
    "        \"\"\"\n",
    "        phrase_list = set()\n",
    "        # Create contender phrases from sentences.\n",
    "        for sentence in sentences:\n",
    "            word_list = [word.lower() for word in wordpunct_tokenize(sentence)]\n",
    "            phrase_list.update(self._get_phrase_list_from_words(word_list))\n",
    "        return phrase_list\n",
    "\n",
    "    def _get_phrase_list_from_words(self, word_list):\n",
    "        \"\"\"Method to create contender phrases from the list of words that form\n",
    "        a sentence by dropping stopwords and punctuations and grouping the left\n",
    "        words into phrases. Only phrases in the given length range (both limits\n",
    "        inclusive) would be considered to build co-occurrence matrix. Ex:\n",
    "        Sentence: Red apples, are good in flavour.\n",
    "        List of words: ['red', 'apples', \",\", 'are', 'good', 'in', 'flavour']\n",
    "        List after dropping punctuations and stopwords.\n",
    "        List of words: ['red', 'apples', *, *, good, *, 'flavour']\n",
    "        List of phrases: [('red', 'apples'), ('good',), ('flavour',)]\n",
    "        List of phrases with a correct length:\n",
    "        For the range [1, 2]: [('red', 'apples'), ('good',), ('flavour',)]\n",
    "        For the range [1, 1]: [('good',), ('flavour',)]\n",
    "        For the range [2, 2]: [('red', 'apples')]\n",
    "        :param word_list: List of words which form a sentence when joined in\n",
    "                          the same order.\n",
    "        :return: List of contender phrases that are formed after dropping\n",
    "                 stopwords and punctuations.\n",
    "        \"\"\"\n",
    "        groups = groupby(word_list, lambda x: x not in self.to_ignore)\n",
    "        phrases = [tuple(group[1]) for group in groups if group[0]]\n",
    "        return list(\n",
    "            filter(\n",
    "                lambda x: self.min_length <= len(x) <= self.max_length, phrases\n",
    "            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rl_list=[]\n",
    "number_of_asins_on_which_keyword_separators_should_be_applied= 100\n",
    "counter=0\n",
    "rl_dict={}\n",
    "TFIDF_dict={}\n",
    "vec, map = TF_IDF_all(asin_dict)\n",
    "\n",
    "for i in asin_dict.keys():\n",
    "    if counter < number_of_asins_on_which_keyword_separators_should_be_applied:\n",
    "#         print asin_dict[i]\n",
    "        c = Rake()\n",
    "        c.extract_keywords_from_text(asin_dict[i])\n",
    "        rl_dict[i]= c.rank_list\n",
    "        counter+=1\n",
    "        ###########################\n",
    "        # Run TF-IDF\n",
    "        ###########################\n",
    "#         #test_list = [0, 2, 3, 4, 8, 9, 12, 13, 14]\n",
    "#         test_list = [0]\n",
    "\n",
    "#         for i in test_list:\n",
    "#             my_asin = asin_dict.keys()[i]\n",
    "#             print my_asin\n",
    "#         print asin_title_map[i]\n",
    "\n",
    "        TFIDF_dict[i] = TF_IDF_asin(i, asin_dict, vec, map, 10)\n",
    "#             print keywords\n",
    "    else:\n",
    "        break\n",
    "        #     rl_list.append(c.rank_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# d = Rake()\n",
    "# d.extract_keywords_from_text('I love cats and cats')\n",
    "# print d.rank_list\n",
    "# print d.ranked_phrases\n",
    "print len(TFIDF_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srishti/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:34: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/Users/srishti/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:37: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/Users/srishti/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:76: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srishti/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:90: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/Users/srishti/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:79: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#converts reviews to embedding dict where key is the ASIN of a book\n",
    "count=0\n",
    "review_dict={}\n",
    "TFIDF_review_dict={}\n",
    "\n",
    "lower_cutoff_for_word_to_be_considered=1#model parameter\n",
    "TFIDF_lower_cutoff_for_word_to_be_considered=0.0#model parameter\n",
    "\n",
    "number_of_reviews_for_clustering=100#select how many reviews are being used for clustering, small number reduces computation time. \n",
    "\n",
    "max_word_per_review= 10#model parameter\n",
    "TFIDF_max_word_per_review= 10#model parameter\n",
    "\n",
    "\n",
    "if number_of_reviews_for_clustering > len(rl_dict.keys()):\n",
    "    print (\"number_of_reviews_for_clustering too large!!\")\n",
    "    print(\"number of reviews= \" + str(len(rl_dict.keys()))+ \" requested \" + str(number_of_reviews_for_clustering))\n",
    "else:\n",
    "    for i in rl_dict.keys():\n",
    "        normalization_factor=0\n",
    "#         print i\n",
    "        if count< number_of_reviews_for_clustering :\n",
    "            print count\n",
    "            count +=1\n",
    "    #         print rl_dict[i]\n",
    "        #     print rl_list[i][0]\n",
    "            count_of_words_used=0\n",
    "#             print \"entering RAKE\"\n",
    "            for j in rl_dict[i]:\n",
    "#                 print \"entered RAKE\"\n",
    "                if count_of_words_used < max_word_per_review:\n",
    "                    count_of_words_used+=1\n",
    "                    if j[0] > lower_cutoff_for_word_to_be_considered:\n",
    "                        if j[1] not in embeddings_index.keys():\n",
    "                            for k in j[1].split():\n",
    "                #                 print (\"k=\" + k)\n",
    "                                if k in embeddings_index.keys():\n",
    "                                    if i not in review_dict.keys():\n",
    "\n",
    "                                        review_dict[i]= j[0]* embeddings_index[k] \n",
    "                                        normalization_factor+=1\n",
    "                                    else:\n",
    "                                        review_dict[i]+= j[0]* embeddings_index[k] \n",
    "                                        normalization_factor+=1\n",
    "        #                         else:\n",
    "        #                             print k\n",
    "                        else:\n",
    "                            if j[1] in embeddings_index.keys():\n",
    "                #                 print (\"j=\" + j[1])\n",
    "                    #             review_dict[i]+= rl_list[j][0]* embeddings_index[j][1]\n",
    "                                if i not in review_dict.keys():\n",
    "                                    review_dict[i]= j[0]* embeddings_index[j[1]]\n",
    "                                    normalization_factor+=1\n",
    "                                else:\n",
    "                                    review_dict[i]+= j[0]* embeddings_index[j[1]]\n",
    "                                    normalization_factor+=1\n",
    "        #                     else:\n",
    "        #                         print j[1]\n",
    "#             print (\"entering normalization\" + str(i))\n",
    "            if normalization_factor >0:\n",
    "#                     review_dict[i]= review_dict[i]/ normalization_factor\n",
    "                [z/normalization_factor for z in review_dict[i]]\n",
    "#             print (\"RAKE done..\")\n",
    "\n",
    "    #TF-IDF converts reviews to embedding dict where key is the ASIN of a book\n",
    "#             print (\"RAKE done..\")\n",
    "            TFIDF_normalization_factor=0\n",
    "            TFIDF_count_of_words_used=0\n",
    "#             print TFIDF_dict[i]\n",
    "#             print \"entering TFIDF\"\n",
    "            for j in TFIDF_dict[i]:\n",
    "                \n",
    "                if TFIDF_count_of_words_used < max_word_per_review:\n",
    "                    TFIDF_count_of_words_used+=1\n",
    "                    if j[0] > TFIDF_lower_cutoff_for_word_to_be_considered:\n",
    "                        if j[1] not in embeddings_index.keys():\n",
    "                            for k in j[1].split():\n",
    "#                                 print (\"k=\" + k)\n",
    "                                if k in embeddings_index.keys():\n",
    "#                                     print (\"k=\" + k)\n",
    "                                    if i not in TFIDF_review_dict.keys():\n",
    "                                        TFIDF_review_dict[i]= j[0]* embeddings_index[k] \n",
    "                                        TFIDF_normalization_factor+=1\n",
    "                                    else:\n",
    "                                        TFIDF_review_dict[i]+= j[0]* embeddings_index[k] \n",
    "                                        TFIDF_normalization_factor+=1\n",
    "        #                         else:\n",
    "        #                             print k\n",
    "                        else:\n",
    "                            if j[1] in embeddings_index.keys():\n",
    "#                                 print (\"j=\" + j[1])\n",
    "                                if i not in TFIDF_review_dict.keys():\n",
    "                                    TFIDF_review_dict[i]= j[0]* embeddings_index[j[1]]\n",
    "                                    TFIDF_normalization_factor+=1\n",
    "                                else:\n",
    "                                    TFIDF_review_dict[i]+= j[0]* embeddings_index[j[1]]\n",
    "                                    TFIDF_normalization_factor+=1\n",
    "        #                     else:\n",
    "        #                         print j[1]\n",
    "#             print (\"entering TFIDF Normalization\" + str(i))\n",
    "#             print TFIDF_review_dict\n",
    "            if TFIDF_normalization_factor >0:\n",
    "#                     review_dict[i]= review_dict[i]/ normalization_factor\n",
    "                [z/TFIDF_normalization_factor for z in TFIDF_review_dict[i]]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print len(TFIDF_review_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TF-IDF converts reviews to embedding dict where key is the ASIN of a book\n",
    "# count=0\n",
    "# TFIDF_review_dict={}\n",
    "# number_of_reviews_for_clustering=5#select how many reviews are being used for clustering, small number reduces computation time. \n",
    "# if number_of_reviews_for_clustering > len(TFIDF_dict.keys()):\n",
    "#     print (\"number_of_reviews_for_clustering too large!!\")\n",
    "#     print(\"number of reviews= \" + str(len(rl_dict.keys()))+ \" requested \" + str(number_of_reviews_for_clustering))\n",
    "# else:\n",
    "#     max_word_per_review= 10#model parameter\n",
    "#     lower_cutoff_for_word_to_be_considered=0.0#model parameter\n",
    "#     for i in TFIDF_dict.keys():\n",
    "#         normalization_factor=0\n",
    "# #         print i\n",
    "#         if count< number_of_reviews_for_clustering :\n",
    "#             count +=1\n",
    "#             count_of_words_used=0\n",
    "# #             print TFIDF_dict[i]\n",
    "#             for j in TFIDF_dict[i]:\n",
    "#                 print j\n",
    "#                 if count_of_words_used < max_word_per_review:\n",
    "#                     count_of_words_used+=1\n",
    "#                     if j[0] > lower_cutoff_for_word_to_be_considered:\n",
    "#                         if j[1] not in embeddings_index.keys():\n",
    "#                             for k in j[1].split():\n",
    "#                                 print (\"k=\" + k)\n",
    "#                                 if k in embeddings_index.keys():\n",
    "#                                     if i not in TFIDF_review_dict.keys():\n",
    "#                                         TFIDF_review_dict[i]= j[0]* embeddings_index[k] \n",
    "#                                         normalization_factor+=1\n",
    "#                                     else:\n",
    "#                                         TFIDF_review_dict[i]+= j[0]* embeddings_index[k] \n",
    "#                                         normalization_factor+=1\n",
    "#         #                         else:\n",
    "#         #                             print k\n",
    "#                         else:\n",
    "#                             if j[1] in embeddings_index.keys():\n",
    "#                                 print (\"j=\" + j[1])\n",
    "#                                 if i not in TFIDF_review_dict.keys():\n",
    "#                                     TFIDF_review_dict[i]= j[0]* embeddings_index[j[1]]\n",
    "#                                     normalization_factor+=1\n",
    "#                                 else:\n",
    "#                                     TFIDF_review_dict[i]+= j[0]* embeddings_index[j[1]]\n",
    "#                                     normalization_factor+=1\n",
    "#         #                     else:\n",
    "#         #                         print j[1]\n",
    "#                 if normalization_factor >0:\n",
    "# #                     review_dict[i]= review_dict[i]/ normalization_factor\n",
    "#                     [z/normalization_factor for z in TFIDF_review_dict[i]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "count =0\n",
    "for i in review_dict.keys():\n",
    "    if i not in TFIDF_review_dict.keys():\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dict_list=[]\n",
    "TFIDF_review_dict_list=[]\n",
    "for i in review_dict.keys():\n",
    "    review_dict_list.append(review_dict[i])\n",
    "    TFIDF_review_dict_list.append(TFIDF_review_dict[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 9 0 0 0 6 2 6 0 0 7 2 0 0 5 9 6 2 6 3 0 0 9 0 6 0 0 6 6 6 6 0 6 6 6 0 0\n",
      " 6 7 6 0 7 0 0 9 1 9 9 9 8 0 9 9 6 6 6 0 0 0 0 9 7 0 0 6 0 6 9 0 6 6 6 0 6\n",
      " 0 6 9 0 6 9 7 0 0 0 6 6 0 6 6 0 6 2 6 7 4 0 7 0 1 0]\n",
      "[4 7 2 4 7 7 6 7 3 0 5 5 7 9 5 5 2 0 2 0 0 0 5 5 0 0 4 0 5 4 0 0 0 4 0 0 7\n",
      " 0 1 5 5 5 5 7 7 0 0 7 0 5 3 0 5 0 0 7 9 3 3 4 5 4 9 0 2 7 7 5 9 0 0 7 2 5\n",
      " 3 0 7 0 5 5 5 9 8 7 0 0 3 0 0 3 2 5 4 5 7 0 5 9 5 4]\n"
     ]
    }
   ],
   "source": [
    "#holy K-means\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit_predict(review_dict_list)\n",
    "TFIDF_kmeans= KMeans(n_clusters=10, random_state=0).fit_predict(TFIDF_review_dict_list)\n",
    "print kmeans\n",
    "print TFIDF_kmeans\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAKE_Clustered Titles\n",
      "TFIDF_Clustered Titles\n"
     ]
    }
   ],
   "source": [
    "#matches the embeddings of review to a title\n",
    "clusteredTitles= collections.defaultdict(list)\n",
    "for i in range(0, len(kmeans)):\n",
    "    for asin_value, word2VecList in review_dict.items():\n",
    "        if (word2VecList == review_dict_list[i]).all():\n",
    "#             print asin_value\n",
    "            clusteredTitles[kmeans[i]].append(asin_title_map[asin_value])\n",
    "            break\n",
    "print (\"RAKE_Clustered Titles\")\n",
    "# print clusteredTitles\n",
    "\n",
    "TFIDF_clusteredTitles= collections.defaultdict(list)\n",
    "for i in range(0, len(TFIDF_kmeans)):\n",
    "    for asin_value, word2VecList in TFIDF_review_dict.items():\n",
    "        if (word2VecList == TFIDF_review_dict_list[i]).all():\n",
    "#             print asin_value\n",
    "            TFIDF_clusteredTitles[TFIDF_kmeans[i]].append(asin_title_map[asin_value])\n",
    "            break\n",
    "print (\"TFIDF_Clustered Titles\")\n",
    "# print TFIDF_clusteredTitles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAKE_Cluster Number: 0['Tweezerman  Nose Hair Clipper', 'NuGo Organic Nutrition Bar, Dark Double Chocolate, 1.76-Ounce Bars (Pack of 12)', 'Firehouse Moustache Wax, Light', 'Now Foods Slippery Elm 400mg, Capsules, 100-Count', 'Trojan Bareskin Lubricated Condoms 10pc (3 Pack)', \"Dental Floss Smart Floss Dr. Tung's 30 yd String\", 'derma e Psorzema, Natural Relief for Scaling, Flaking, and Itching, 4 Ounce (113 g)', 'Soft Scrub with Bleach Cleanser, 24-Ounce (Pack of 3)', 'Trojan Vibrating Tri-phoria', 'PowerFactor AA Alkaline Battery 24 Pack', 'Diastix Reagent Strips for Urinalysis to test urine Glucose - 50 Strips', 'Dymatize Nutrition BCAA Complex 5050 Powder, 10.7 Ounce', 'Truform 8810,  Compression Stockings, Anti-Embolism, Thigh High, Closed-Toe, 18 mmHg, Beige, X-Large', 'Mighty Bright 87022 Wallet Magnifier w/ LED Light, Silver', 'Aveeno 1% Hydrocortisone Anti-Itch Cream, Maximum Strength, 1-Ounce Tubes (Pack of 4)', 'Terry Naturally Curamin, 60 Caps', 'Source Naturals Essential Enzymes 500 Mg Vegetarian Capsules, 120-Count', \"Delsym Children's Cough Suppressant, Orange, 5 Ounce\", 'Smartek Battery Operated Fabric Clothes Shaver - Black', 'Auric Blends - Sandalwood Vanilla Body Oil', 'Crest Complete Multi-Benefit Whitening + Scope Outlast Long Lasting Mint Flavor Toothpaste 5.8 Oz', 'Jabon Zote Blanco Finas Escamas Para Lavadora (Laundry Flakes for Washiing Machines), 17.6 Oz., (Pack of 1)', 'Ox Bile 125 mg 180 Capsules', 'TOUCH N BROW Razor (3 Pcs)', 'Drive Medical Toilet Safety Frame, White', 'Bona Stone Tile and Laminate Floor Cleaner Refill, 128-Ounce', '1300 mg Acai  Juice Extreem TM (3 Bottles) New Stronger Potency HIGH POTENCY ACAI Berry Natural Nutrition, Energy 3 Months 180 Caps, 1300 Mg, Acai Juice Extreme', 'Master Series Jizz Water Based Lube, Semen Scented, 8.5 Ounce', 'New Chapter Organics, Berry Green, Vegetarian Capsules, 90-Count', 'Kleenex 2-Ply White Facial Tissue, 10-Pack Bundle (230 tissues per box)', 'Waterpik Waterflosser Ultra And Waterpik Cordless Plus Combo Pack Includes 12 Accessory Tips &amp; Travel Case', 'Cleanstream XL Lubricant Launcher', 'Epilady EP-803-17 Face-Epil Facial and Sensitive Areas Epilator', 'Nivea Lip Butter Loose Tin, Raspberry Rose Kiss, 0.59 Ounce', 'Dynamic Health Nopal Gold - 100% Pure Organic Certified Nopal Juice 32oz, 32 Fluid Ounce', 'Sally Hansen Clinical Lipcare Collection Peptide Lip Line Treatment, 0.42 Ounce', 'Boericke &amp; Tafel Arniflora Arnica Natural Topical Pain Reliever Gel, Maximum Strength 2.75oz (pack of 2)', 'Faultless Tiny Kit (Reusable Douche) - 16 Fl Oz Capacity', 'Diamond Edge Professional Straight Razor Includes 5 double edge blades']\n",
      "RAKE_Cluster Number: 1[\"Degree Clinical Protection, Men's Anti-perspirant and Deodorant, Clean, 1.7-Ounce Stick (Pack of 2)\", 'Ecotones Sound + Sleep Machine, Model ASM1002']\n",
      "RAKE_Cluster Number: 2['Natural Factors Wild Alaskan Salmon Oil 1000mg Softgels, 180-Count', 'Energizer Recharge Value Battery Charger', '2013 Hammer Nutrition Complex Carbohydrate Energy Gel', 'Duracell 80226938 CopperTop Alkaline-Manganese Dioxide Battery with Duralock Power Preserve Technology, AA Size, 1.5V, (Pack of 14)']\n",
      "RAKE_Cluster Number: 3['Febreze Thai Dragon Fruit Deodorizing Powder Endorsed by BISSELL, 32 ounces']\n",
      "RAKE_Cluster Number: 4['Move Free Advanced Glucosamine Nutritional Supplements Gummies, 70 Count']\n",
      "RAKE_Cluster Number: 5['Air Wick Scented Oil Triple Refill Relaxation, Apple Cinnamon Medley, 0.67 Ounce Containers']\n",
      "RAKE_Cluster Number: 6['Nivea Dry Comfort Deodorant Antiperspirant Roll-on 50 ml', 'Ice Pack (6x10 Size)', 'Sleep Essentials 60 Caps', 'Blue Moon Timer and Stopwatch', 'URS Urinalysis Strips For Ketone - 100 ea', 'BISSELL Flip-!t Select Hard Floor Cleaner with Heat, 7340', \"One a Day Women's Vitacraves Gummies, 100 Count\", 'Pumpkin Patch Premium Grade Fragrance Oils - 10ml - Scented Oil', 'Teeth Whitening Light Kit with Photo Initiator gel of 44%', '3M Medipore H Soft Cloth Surgical Tape - 4&quot; wide by 10 yards', 'SimplyBeautiful 100% Pure Badger Brush with Chrome Handle - *Special Price*', 'Omron ComFit Cuff H-CL22, Replacement Cuff for HEM-711DLX, HEM-780 and HEM-790IT.', 'Blush G-spot Slimline Vibrator, Pink', \"Doctor's Best 20 Mg Lutein Esters Vegetarian Capsules, 120 Count\", 'Zud Multi-Purpose Cream Cleanser: 19 OZ', \"Microfiber Cloth, Soft, Scratch-free Cleaning and Dusting Towel-for Automotive, Electronics, Health and Personal, and Home and Kitchen, Keep Your Windows Clean in Your House and Car. Keep Your Car's Showroom Shine, Bonus Pk. Satisfaction Guarantee.\", 'Sony 377 - SR626SW Button Cell Battery', '4th Generation Dr Mom LED POCKET Otoscope with Protective Foam Lined Case', 'Garcinia Cambogia Extract Pure Plus - Clinically Proven Natural Weight Loss, Appetite Suppressant and Fat Burning - Pure 50% HCA Extract - 1000 mg Per Serving Per 2 Capsules - As Seen on TV - 100% Satisfaction Guarantee - Plus A FREE BONUS REPORT On How To Accelerate Your Weight Loss!', 'Drive Medical Walker Basket, White', 'Nicotine Transdermal System Patch, Stop Smoking Aid, 7 mg, Step 3, 14 patches', 'Now Foods Candida Support, 90 Vcaps (Pack of 2)', 'Clotrimazole, AF Antifungal AthleteS Foot Topical Solution 1 Percent (Generic Lotrimin) - 10 Ml', 'Bausch &amp; Lomb Sight Savers Premoistened Lens Cleaning Tissues - 100 Count, 2 pk.', 'Hitachi Magic Wand Massager Only', 'Duracell Coppertop MN1500 AA Batteries , 100 Pack Count', 'Le Couvent des Minimes Eau des Minimes Everyday Deodorant with Alum Stone, 1.7 oz', 'Nature Made Vitamin D3 2000 IU, Value Size, 220-Count', 'Mueller Adjustable Lumbar Back Brace, Black, Plus Size, 1-Count Package', 'Boiron Homeopathic Medicine Oscillococcinum for Flu- Box of 6x 0.04oz Doses (Pack of 2 boxes)', None]\n",
      "RAKE_Cluster Number: 7['Telebrands Earth to skin- Heeltastic intensive heel therapy 2oz 57g', 'Professional Water Resistant Heavy Duty Steel Nose Trimmer with LED light. Backed by a Lifetime Guarantee', 'RockTape Kinesiology Tape for  Athletes (2-Inch x 16.4-Feet)', 'Sinus Plumber Horseradish and Pepper Nasal Spray - Natural Allergy Relief', \"Dr. Scholl's Men's Over-the-calf Compression 1 Pair Sock\", 'Charmin Ultra Strong, 12 Mega Rolls (Pack of 4)', 'Glide Pro-Health For Life Smooth Mint Floss 35 Meters']\n",
      "RAKE_Cluster Number: 8['Charmin Ultra Soft, Mega Rolls, 6 Count Packs (Pack of 3) 18 Total Rolls']\n",
      "RAKE_Cluster Number: 9['Orajel Severe Toothache Pain Relief Cream', 'Wholesomes Sweetners - Organic Molasses, 16 oz liquid', \"Old Spice High Endurance, Original Scent Men's Anti-Perspirant &amp; Deodorant 3 Oz (Pack of 6)\", \"Nature's Way Scullcap Herb, 100 Capsule\", \"Nature's Best Zero Carb Isopure, Strawberries and Cream, 7.5-Pound Tub\", 'Twinlab Super E-Complex 400 IU, 250 Softgels', 'PLANETARY HERBALS Triphala Gold Ayurvedic Herbal Supplement, 1000 Mg, 120 Count', 'Gold Bond Triple Action Medicated Body Powder -- 10 oz', 'Saffron Extract- Appetite Suppressant | 100% Pure Premium Saffron Extract | 88.5mg - 90 Veggie Capsules |1 Pill Per Serving', 'Clearblue Advanced Pregnancy Test With Weeks Estimator 3 Count', 'Thera-Band Light Flex Bar', 'Premier Nutrition High Protein Shake, Vanilla,  11 oz.,18 Count', 'Amberen Healthy Choice for Menopause, 60-Count']\n",
      "TFIDF_Cluster Number: 0[\"Dental Floss Smart Floss Dr. Tung's 30 yd String\", '2013 Hammer Nutrition Complex Carbohydrate Energy Gel', 'Febreze Thai Dragon Fruit Deodorizing Powder Endorsed by BISSELL, 32 ounces', 'Trojan Vibrating Tri-phoria', 'PowerFactor AA Alkaline Battery 24 Pack', 'URS Urinalysis Strips For Ketone - 100 ea', 'Dymatize Nutrition BCAA Complex 5050 Powder, 10.7 Ounce', 'BISSELL Flip-!t Select Hard Floor Cleaner with Heat, 7340', 'Teeth Whitening Light Kit with Photo Initiator gel of 44%', 'Mighty Bright 87022 Wallet Magnifier w/ LED Light, Silver', '3M Medipore H Soft Cloth Surgical Tape - 4&quot; wide by 10 yards', 'Omron ComFit Cuff H-CL22, Replacement Cuff for HEM-711DLX, HEM-780 and HEM-790IT.', 'Aveeno 1% Hydrocortisone Anti-Itch Cream, Maximum Strength, 1-Ounce Tubes (Pack of 4)', 'Blush G-spot Slimline Vibrator, Pink', \"Degree Clinical Protection, Men's Anti-perspirant and Deodorant, Clean, 1.7-Ounce Stick (Pack of 2)\", \"Nature's Best Zero Carb Isopure, Strawberries and Cream, 7.5-Pound Tub\", 'PLANETARY HERBALS Triphala Gold Ayurvedic Herbal Supplement, 1000 Mg, 120 Count', 'Gold Bond Triple Action Medicated Body Powder -- 10 oz', 'Zud Multi-Purpose Cream Cleanser: 19 OZ', \"Microfiber Cloth, Soft, Scratch-free Cleaning and Dusting Towel-for Automotive, Electronics, Health and Personal, and Home and Kitchen, Keep Your Windows Clean in Your House and Car. Keep Your Car's Showroom Shine, Bonus Pk. Satisfaction Guarantee.\", 'Bona Stone Tile and Laminate Floor Cleaner Refill, 128-Ounce', 'Drive Medical Walker Basket, White', 'Nicotine Transdermal System Patch, Stop Smoking Aid, 7 mg, Step 3, 14 patches', 'Bausch &amp; Lomb Sight Savers Premoistened Lens Cleaning Tissues - 100 Count, 2 pk.', 'Waterpik Waterflosser Ultra And Waterpik Cordless Plus Combo Pack Includes 12 Accessory Tips &amp; Travel Case', 'Duracell Coppertop MN1500 AA Batteries , 100 Pack Count', 'Le Couvent des Minimes Eau des Minimes Everyday Deodorant with Alum Stone, 1.7 oz', 'Nature Made Vitamin D3 2000 IU, Value Size, 220-Count', 'Mueller Adjustable Lumbar Back Brace, Black, Plus Size, 1-Count Package', 'Boericke &amp; Tafel Arniflora Arnica Natural Topical Pain Reliever Gel, Maximum Strength 2.75oz (pack of 2)']\n",
      "TFIDF_Cluster Number: 1['Professional Water Resistant Heavy Duty Steel Nose Trimmer with LED light. Backed by a Lifetime Guarantee']\n",
      "TFIDF_Cluster Number: 2['NuGo Organic Nutrition Bar, Dark Double Chocolate, 1.76-Ounce Bars (Pack of 12)', 'Sleep Essentials 60 Caps', 'Blue Moon Timer and Stopwatch', '4th Generation Dr Mom LED POCKET Otoscope with Protective Foam Lined Case', 'New Chapter Organics, Berry Green, Vegetarian Capsules, 90-Count', 'Boiron Homeopathic Medicine Oscillococcinum for Flu- Box of 6x 0.04oz Doses (Pack of 2 boxes)']\n",
      "TFIDF_Cluster Number: 3['Trojan Bareskin Lubricated Condoms 10pc (3 Pack)', 'Auric Blends - Sandalwood Vanilla Body Oil', 'Jabon Zote Blanco Finas Escamas Para Lavadora (Laundry Flakes for Washiing Machines), 17.6 Oz., (Pack of 1)', 'Ox Bile 125 mg 180 Capsules', 'Kleenex 2-Ply White Facial Tissue, 10-Pack Bundle (230 tissues per box)', 'Dynamic Health Nopal Gold - 100% Pure Organic Certified Nopal Juice 32oz, 32 Fluid Ounce', 'Sally Hansen Clinical Lipcare Collection Peptide Lip Line Treatment, 0.42 Ounce']\n",
      "TFIDF_Cluster Number: 4['Tweezerman  Nose Hair Clipper', 'Firehouse Moustache Wax, Light', 'Truform 8810,  Compression Stockings, Anti-Embolism, Thigh High, Closed-Toe, 18 mmHg, Beige, X-Large', 'Pumpkin Patch Premium Grade Fragrance Oils - 10ml - Scented Oil', 'SimplyBeautiful 100% Pure Badger Brush with Chrome Handle - *Special Price*', 'TOUCH N BROW Razor (3 Pcs)', 'Sinus Plumber Horseradish and Pepper Nasal Spray - Natural Allergy Relief', None, 'Diamond Edge Professional Straight Razor Includes 5 double edge blades']\n",
      "TFIDF_Cluster Number: 5['Telebrands Earth to skin- Heeltastic intensive heel therapy 2oz 57g', 'Energizer Recharge Value Battery Charger', 'Air Wick Scented Oil Triple Refill Relaxation, Apple Cinnamon Medley, 0.67 Ounce Containers', 'Wholesomes Sweetners - Organic Molasses, 16 oz liquid', \"Old Spice High Endurance, Original Scent Men's Anti-Perspirant &amp; Deodorant 3 Oz (Pack of 6)\", 'Diastix Reagent Strips for Urinalysis to test urine Glucose - 50 Strips', \"One a Day Women's Vitacraves Gummies, 100 Count\", \"Doctor's Best 20 Mg Lutein Esters Vegetarian Capsules, 120 Count\", 'Source Naturals Essential Enzymes 500 Mg Vegetarian Capsules, 120-Count', 'RockTape Kinesiology Tape for  Athletes (2-Inch x 16.4-Feet)', \"Delsym Children's Cough Suppressant, Orange, 5 Ounce\", 'Charmin Ultra Soft, Mega Rolls, 6 Count Packs (Pack of 3) 18 Total Rolls', 'Saffron Extract- Appetite Suppressant | 100% Pure Premium Saffron Extract | 88.5mg - 90 Veggie Capsules |1 Pill Per Serving', 'Clearblue Advanced Pregnancy Test With Weeks Estimator 3 Count', 'Thera-Band Light Flex Bar', 'Clotrimazole, AF Antifungal AthleteS Foot Topical Solution 1 Percent (Generic Lotrimin) - 10 Ml', 'Hitachi Magic Wand Massager Only', 'Amberen Healthy Choice for Menopause, 60-Count', \"Dr. Scholl's Men's Over-the-calf Compression 1 Pair Sock\", 'Duracell 80226938 CopperTop Alkaline-Manganese Dioxide Battery with Duralock Power Preserve Technology, AA Size, 1.5V, (Pack of 14)', 'Charmin Ultra Strong, 12 Mega Rolls (Pack of 4)', 'Glide Pro-Health For Life Smooth Mint Floss 35 Meters', 'Ecotones Sound + Sleep Machine, Model ASM1002']\n",
      "TFIDF_Cluster Number: 6['Natural Factors Wild Alaskan Salmon Oil 1000mg Softgels, 180-Count']\n",
      "TFIDF_Cluster Number: 7['Orajel Severe Toothache Pain Relief Cream', 'Now Foods Slippery Elm 400mg, Capsules, 100-Count', 'Nivea Dry Comfort Deodorant Antiperspirant Roll-on 50 ml', 'Ice Pack (6x10 Size)', 'derma e Psorzema, Natural Relief for Scaling, Flaking, and Itching, 4 Ounce (113 g)', 'Terry Naturally Curamin, 60 Caps', 'Smartek Battery Operated Fabric Clothes Shaver - Black', \"Nature's Way Scullcap Herb, 100 Capsule\", 'Twinlab Super E-Complex 400 IU, 250 Softgels', 'Sony 377 - SR626SW Button Cell Battery', '1300 mg Acai  Juice Extreem TM (3 Bottles) New Stronger Potency HIGH POTENCY ACAI Berry Natural Nutrition, Energy 3 Months 180 Caps, 1300 Mg, Acai Juice Extreme', 'Garcinia Cambogia Extract Pure Plus - Clinically Proven Natural Weight Loss, Appetite Suppressant and Fat Burning - Pure 50% HCA Extract - 1000 mg Per Serving Per 2 Capsules - As Seen on TV - 100% Satisfaction Guarantee - Plus A FREE BONUS REPORT On How To Accelerate Your Weight Loss!', 'Now Foods Candida Support, 90 Vcaps (Pack of 2)', 'Premier Nutrition High Protein Shake, Vanilla,  11 oz.,18 Count', 'Nivea Lip Butter Loose Tin, Raspberry Rose Kiss, 0.59 Ounce', 'Move Free Advanced Glucosamine Nutritional Supplements Gummies, 70 Count']\n",
      "TFIDF_Cluster Number: 8['Epilady EP-803-17 Face-Epil Facial and Sensitive Areas Epilator']\n",
      "TFIDF_Cluster Number: 9['Soft Scrub with Bleach Cleanser, 24-Ounce (Pack of 3)', 'Crest Complete Multi-Benefit Whitening + Scope Outlast Long Lasting Mint Flavor Toothpaste 5.8 Oz', 'Drive Medical Toilet Safety Frame, White', 'Master Series Jizz Water Based Lube, Semen Scented, 8.5 Ounce', 'Cleanstream XL Lubricant Launcher', 'Faultless Tiny Kit (Reusable Douche) - 16 Fl Oz Capacity']\n"
     ]
    }
   ],
   "source": [
    "for i in clusteredTitles.keys():\n",
    "    print \"RAKE_Cluster Number: \" + str(i)+ str(clusteredTitles[i])\n",
    "\n",
    "for i in TFIDF_clusteredTitles.keys():\n",
    "    print \"TFIDF_Cluster Number: \" + str(i)+ str(TFIDF_clusteredTitles[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B00AZOOW6O\n"
     ]
    }
   ],
   "source": [
    "#computation for example in the poster\n",
    "name='Duracell 80226938 CopperTop Alkaline-Manganese Dioxide Battery with Duralock Power Preserve Technology, AA Size, 1.5V, (Pack of 14)'\n",
    "for j in asin_title_map.keys():\n",
    "    if asin_title_map[j] == name:\n",
    "        print j\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation for example in the poster\n",
    "pos_reviews_B00AZOOW6O = ''\n",
    "neg_reviews_B00AZOOW6O = ''\n",
    "\n",
    "for i in data:\n",
    "    if i['asin'] == 'B00AZOOW6O':\n",
    "#     asin_dict[i['asin']].append(i['reviewText'])\n",
    "        if i['overall'] >= 4:\n",
    "            pos_reviews_B00AZOOW6O+= i['reviewText']\n",
    "\n",
    "        else:\n",
    "            neg_reviews_B00AZOOW6O+=i['reviewText']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_reviews_B00AZOOW6O= I buy Duracell based on previous experience.  The ProCell batteries are what I've used for years and I have had no issues at all.  I bought standard Coppertops because they were on sale and I see no difference thus far.  They seem to last an appropriate amount of time in remotes and kids toys, which is my main usage.  Given that the ProCell batteries are usually cheaper and just as effective, I have to rate the Coppertops 4 stars.  They work great, but not better than a cheaper alternative.Duracell batteries are about as good as any other high quality battery. One aspect I like of these &#34;Duralock&#34; batteries is that they have a shelf life of about 10 years. I can remember years ago a battery would have a shelf life of about 1 year!  Although I have a bunch of alkalines, when they're gone I'm going rechargables! Rechargables such as Eneloop are high quality and VERY cost effective despite their intial $$$.These Alkaline-Manganese Dioxide batteries seem very well made, arrived promptly with excellent packaging.  Though I've only used a few of them, they seem just fine forflash lights, wireless keep board and mouse for my computer.I ordered these batteries cheaper than what I could find locally, especially with free shipping. You can never have too many batteries around the house for remotes and grand kids toys.These batteries are made in USA and have an expiration date of 2019. I bought some AAA batteries right before this purchase and the seller said &#34;made in USA.&#34; When the batteries arrived, seven were dented with some having battery acid coming out in the package and were made in China. The seller said it was due to hurricane Sandy. I sympathize with the company and the folks that lost so much in the hurricane, but the seller of these AA batteries was in the same area and I had no problem with them nor their advertising. I will purchase these batteries again the Amazon.com and Duracell.I purchased these batteries a week ago and was satisfied for the value.  Getting the 28 pack last year was a far better value, however getting less batteries for the same price appears to the cost of doing business. Regarding freshness, these were very fresh batteries with 12 years of guaranteed life through 2022.These batteries is ultra strong and last a long time. Very good quality to get for any electronics. good job duracelli have used duracell batteries for years, as you all know they are the best batteries that are out thereI love the Duracell batteries above all brands.  These are fresh and supply power at needed levels. I highly recommend.All you have to do is plan a little ahead and buy batteries here. Those impulse buys at the check out counter at retailers is where you get hit. These are great for the price to have on hand at home.I love that you can add batteries to your Amazon order! It's so annoying to have to run to the store every time batteries are needed.i HAVE ONLY USED A FEW OF THEM IN MY FLAMELESS CANDLES, AND THEY SEEM FINE SO FAR.  I THINK THE PRICE IS VERY GOOD.The batteries worked fine, as expected.  They didn't seem to drain really fast or have any issues.  Used them in kids toys and remotes, worked just fine.great deal on these batteries and with the storm season approaching always need x-tras - stock up now at this low price\n",
      "neg_reviews_B00AZOOW6O =Using these in my 6 year old Kodak C180 digital camera. Traditional Copper Tops last longer. What's the big deal beyond a bigger price?It pains me to write this as most of my purchases with Amazon are 5 stars, but these batteries appear to be fraud!  First the unlabeled box made to hold 20 was opened and there are oily surfaced 14 batteries.  Then I checked the labels and two were blistering and had to be pitched immediately.  Thinking these were the ones leaking the oil, I took a rag and cleaned to oil off the rest of the batteries.  I found two more batteries with different labels from the rest, and a closer look found that their dates were marked 2015 and the rest were marked 2019.  None of the the advertised 10 yrs shelf life.  I tested each one and found all of them dead.  I then checked the checker by testing them inside an old mouse and it confirmed they were dead on arrival.  I then put 4 of them inside a recharger made for alk batteries, and as they started to recharge, all leaked oil and 2 bubbled a brown substance which ruined a perfectly good charger.  By now, do you think I would trust these batteries inside a children's toy or any of my electronic gear.  NO Way!!!  Cost to return prohibits return, so this warning to those of you who read this to not trust this vendor &#34;utrusted&#34; who appears to be recycling batteries or mfg fraud copies.  As they say, never trust someone who says trust me, don't trust this vendor.  I trusted and got scammed.After answering a question about how sure someone could be about these, I took mine to a known electronics retailer and had these tested.  Due to an error by Amazon's Customer Service, I ended up receiving too many boxes of these batteries.  In each box of 14, there were at least 4 batteries that were no good.  I cancelled my Subscribe & Save subscription.  Since I have more than I ordered, and Amazon refunded the error amount charged to me, it'd cost me more than it's worth to return them, but I will not be reordering them.\n",
      "I buy Duracell based on previous experience.  The ProCell batteries are what I've used for years and I have had no issues at all.  I bought standard Coppertops because they were on sale and I see no difference thus far.  They seem to last an appropriate amount of time in remotes and kids toys, which is my main usage.  Given that the ProCell batteries are usually cheaper and just as effective, I have to rate the Coppertops 4 stars.  They work great, but not better than a cheaper alternative. Duracell batteries are about as good as any other high quality battery. One aspect I like of these &#34;Duralock&#34; batteries is that they have a shelf life of about 10 years. I can remember years ago a battery would have a shelf life of about 1 year!  Although I have a bunch of alkalines, when they're gone I'm going rechargables! Rechargables such as Eneloop are high quality and VERY cost effective despite their intial $$$. These Alkaline-Manganese Dioxide batteries seem very well made, arrived promptly with excellent packaging.  Though I've only used a few of them, they seem just fine forflash lights, wireless keep board and mouse for my computer. Using these in my 6 year old Kodak C180 digital camera. Traditional Copper Tops last longer. What's the big deal beyond a bigger price? It pains me to write this as most of my purchases with Amazon are 5 stars, but these batteries appear to be fraud!  First the unlabeled box made to hold 20 was opened and there are oily surfaced 14 batteries.  Then I checked the labels and two were blistering and had to be pitched immediately.  Thinking these were the ones leaking the oil, I took a rag and cleaned to oil off the rest of the batteries.  I found two more batteries with different labels from the rest, and a closer look found that their dates were marked 2015 and the rest were marked 2019.  None of the the advertised 10 yrs shelf life.  I tested each one and found all of them dead.  I then checked the checker by testing them inside an old mouse and it confirmed they were dead on arrival.  I then put 4 of them inside a recharger made for alk batteries, and as they started to recharge, all leaked oil and 2 bubbled a brown substance which ruined a perfectly good charger.  By now, do you think I would trust these batteries inside a children's toy or any of my electronic gear.  NO Way!!!  Cost to return prohibits return, so this warning to those of you who read this to not trust this vendor &#34;utrusted&#34; who appears to be recycling batteries or mfg fraud copies.  As they say, never trust someone who says trust me, don't trust this vendor.  I trusted and got scammed. I ordered these batteries cheaper than what I could find locally, especially with free shipping. You can never have too many batteries around the house for remotes and grand kids toys.These batteries are made in USA and have an expiration date of 2019. I bought some AAA batteries right before this purchase and the seller said &#34;made in USA.&#34; When the batteries arrived, seven were dented with some having battery acid coming out in the package and were made in China. The seller said it was due to hurricane Sandy. I sympathize with the company and the folks that lost so much in the hurricane, but the seller of these AA batteries was in the same area and I had no problem with them nor their advertising. I will purchase these batteries again the Amazon.com and Duracell. I purchased these batteries a week ago and was satisfied for the value.  Getting the 28 pack last year was a far better value, however getting less batteries for the same price appears to the cost of doing business. Regarding freshness, these were very fresh batteries with 12 years of guaranteed life through 2022. After answering a question about how sure someone could be about these, I took mine to a known electronics retailer and had these tested.  Due to an error by Amazon's Customer Service, I ended up receiving too many boxes of these batteries.  In each box of 14, there were at least 4 batteries that were no good.  I cancelled my Subscribe & Save subscription.  Since I have more than I ordered, and Amazon refunded the error amount charged to me, it'd cost me more than it's worth to return them, but I will not be reordering them. These batteries is ultra strong and last a long time. Very good quality to get for any electronics. good job duracell i have used duracell batteries for years, as you all know they are the best batteries that are out there I love the Duracell batteries above all brands.  These are fresh and supply power at needed levels. I highly recommend. All you have to do is plan a little ahead and buy batteries here. Those impulse buys at the check out counter at retailers is where you get hit. These are great for the price to have on hand at home. I love that you can add batteries to your Amazon order! It's so annoying to have to run to the store every time batteries are needed. i HAVE ONLY USED A FEW OF THEM IN MY FLAMELESS CANDLES, AND THEY SEEM FINE SO FAR.  I THINK THE PRICE IS VERY GOOD. The batteries worked fine, as expected.  They didn't seem to drain really fast or have any issues.  Used them in kids toys and remotes, worked just fine. great deal on these batteries and with the storm season approaching always need x-tras - stock up now at this low price\n"
     ]
    }
   ],
   "source": [
    "#computation for example in the poster\n",
    "print \"pos_reviews_B00AZOOW6O= \" + pos_reviews_B00AZOOW6O \n",
    "print \"neg_reviews_B00AZOOW6O =\" + neg_reviews_B00AZOOW6O\n",
    "print asin_dict['B00AZOOW6O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(36.0, u'storm season approaching always need x'), (13.5, u'28 pack last year'), (13.029411764705882, u'however getting less batteries'), (12.862745098039216, u'store every time batteries'), (12.862745098039216, u'manganese dioxide batteries seem'), (11.333333333333334, u'seller said &# 34'), (9.0, u'wireless keep board'), (9.0, u'duralock &# 34'), (9.0, u'drain really fast'), (9.0, u'could find locally'), (9.0, u'coppertops 4 stars'), (8.666666666666666, u'battery acid coming'), (8.529411764705882, u'many batteries around'), (8.529411764705882, u'aaa batteries right'), (8.333333333333334, u'difference thus far'), (8.25, u'fine forflash lights'), (8.0, u'usa .&# 34'), (8.0, u'grand kids toys'), (8.0, u'good job duracelli'), (8.0, u'bought standard coppertops'), (7.75, u'buy duracell based'), (7.5, u'remember years ago'), (7.5, u'high quality battery'), (7.0, u'cost effective despite'), (6.779411764705882, u'used duracell batteries'), (6.779411764705882, u'batteries worked fine'), (6.333333333333334, u'far better value'), (6.0, u'&# 34'), (5.333333333333334, u'seller said'), (5.029411764705882, u'buy batteries'), (5.0, u'kids toys'), (5.0, u'1 year'), (4.833333333333334, u'high quality'), (4.779411764705882, u'duracell batteries'), (4.666666666666666, u'battery would'), (4.583333333333334, u'seem fine'), (4.529411764705882, u'procell batteries'), (4.529411764705882, u'best batteries'), (4.529411764705882, u'batteries cheaper'), (4.529411764705882, u'batteries arrived'), (4.529411764705882, u'add batteries'), (4.529411764705882, u'aa batteries'), (4.5, u'week ago'), (4.333333333333334, u'long time'), (4.333333333333334, u'good quality'), (4.029411764705882, u'fresh batteries'), (4.0, u'usually cheaper'), (4.0, u'ultra strong'), (4.0, u'supply power'), (4.0, u'shelf life'), (4.0, u'regarding freshness'), (4.0, u'previous experience'), (4.0, u'one aspect'), (4.0, u'main usage'), (4.0, u'little ahead'), (4.0, u'intial $$$.'), (4.0, u'impulse buys'), (4.0, u'highly recommend'), (4.0, u'guaranteed life'), (4.0, u'free shipping'), (4.0, u'flameless candles'), (4.0, u'expiration date'), (4.0, u'excellent packaging'), (4.0, u'cheaper alternative'), (4.0, u'arrived promptly'), (4.0, u'appropriate amount'), (4.0, u'12 years'), (4.0, u'10 years'), (3.666666666666667, u'work great'), (3.666666666666667, u'price appears'), (3.666666666666667, u'low price'), (3.666666666666667, u'great deal'), (3.5, u'well made'), (3.5, u'therei love'), (3.5, u'needed levels'), (3.5, u'hurricane sandy'), (3.5, u'going rechargables'), (3.5, u'get hit'), (3.5, u'amazon order'), (2.5294117647058822, u'batteries'), (2.5, u'last'), (2.5, u'getting'), (2.3333333333333335, u'time'), (2.3333333333333335, u'seller'), (2.3333333333333335, u'seem'), (2.3333333333333335, u'far'), (2.25, u'fine'), (2.25, u'duracell'), (2.0, u'years'), (2.0, u'worked'), (2.0, u'value'), (2.0, u'used'), (2.0, u'usa'), (2.0, u'good'), (2.0, u'effective'), (2.0, u'cost'), (2.0, u'bought'), (2.0, u'better'), (1.6666666666666667, u'price'), (1.6666666666666667, u'great'), (1.5, u'rechargables'), (1.5, u'needed'), (1.5, u'made'), (1.5, u'love'), (1.5, u'hurricane'), (1.5, u'get'), (1.5, u'fresh'), (1.5, u'amazon'), (1.0, u'tras'), (1.0, u'though'), (1.0, u'think'), (1.0, u'sympathize'), (1.0, u'stock'), (1.0, u'seven'), (1.0, u'see'), (1.0, u'satisfied'), (1.0, u'sale'), (1.0, u'run'), (1.0, u'retailers'), (1.0, u'remotes'), (1.0, u'rate'), (1.0, u'purchased'), (1.0, u'purchase'), (1.0, u'problem'), (1.0, u'plan'), (1.0, u'package'), (1.0, u'ordered'), (1.0, u'never'), (1.0, u'much'), (1.0, u'mouse'), (1.0, u'lost'), (1.0, u'like'), (1.0, u'know'), (1.0, u'issues'), (1.0, u'house'), (1.0, u'home'), (1.0, u'hand'), (1.0, u'gone'), (1.0, u'given'), (1.0, u'folks'), (1.0, u'expected'), (1.0, u'especially'), (1.0, u'eneloop'), (1.0, u'electronics'), (1.0, u'due'), (1.0, u'dented'), (1.0, u'counter'), (1.0, u'computer'), (1.0, u'company'), (1.0, u'com'), (1.0, u'china'), (1.0, u'check'), (1.0, u'business'), (1.0, u'bunch'), (1.0, u'brands'), (1.0, u'area'), (1.0, u'annoying'), (1.0, u'although'), (1.0, u'alkalines'), (1.0, u'alkaline'), (1.0, u'advertising'), (1.0, u'2022'), (1.0, u'2019')]\n",
      "[(46.5, u'6 year old kodak c180 digital camera'), (25.0, u'traditional copper tops last longer'), (25.0, u'advertised 10 yrs shelf life'), (12.785714285714285, u'oily surfaced 14 batteries'), (9.0, u'utrusted &# 34'), (9.0, u'sure someone could'), (9.0, u'known electronics retailer'), (9.0, u'big deal beyond'), (8.0, u'vendor &# 34'), (8.0, u'perfectly good charger'), (8.0, u'never trust someone'), (8.0, u'mfg fraud copies'), (8.0, u'error amount charged'), (8.0, u'closer look found'), (7.785714285714286, u'least 4 batteries'), (7.666666666666668, u'return prohibits return'), (7.5, u'unlabeled box made'), (6.5, u'old mouse'), (4.5, u'recharger made'), (4.5, u'put 4'), (4.285714285714286, u'recycling batteries'), (4.285714285714286, u'batteries appear'), (4.285714285714286, u'alk batteries'), (4.0, u'would trust'), (4.0, u'way !!!'), (4.0, u'says trust'), (4.0, u'save subscription'), (4.0, u'pitched immediately'), (4.0, u'ones leaking'), (4.0, u'marked 2019'), (4.0, u'marked 2015'), (4.0, u'many boxes'), (4.0, u'hold 20'), (4.0, u'got scammed'), (4.0, u'electronic gear'), (4.0, u'customer service'), (4.0, u'brown substance'), (4.0, u'bigger price'), (4.0, u'5 stars'), (4.0, u'2 bubbled'), (3.7857142857142856, u'batteries inside'), (3.5, u'took mine'), (3.5, u'leaked oil'), (3.5, u'found two'), (3.5, u'different labels'), (3.5, u'amazon refunded'), (2.5, u'14'), (2.3333333333333335, u'return'), (2.2857142857142856, u'batteries'), (2.0, u'vendor'), (2.0, u'trust'), (2.0, u'good'), (2.0, u'fraud'), (2.0, u'found'), (2.0, u'error'), (2.0, u'box'), (1.5, u'two'), (1.5, u'took'), (1.5, u'oil'), (1.5, u'labels'), (1.5, u'inside'), (1.5, u'amazon'), (1.0, u'write'), (1.0, u'worth'), (1.0, u'warning'), (1.0, u'using'), (1.0, u'trusted'), (1.0, u'toy'), (1.0, u'thinking'), (1.0, u'think'), (1.0, u'testing'), (1.0, u'tested'), (1.0, u'subscribe'), (1.0, u'started'), (1.0, u'since'), (1.0, u'say'), (1.0, u'ruined'), (1.0, u'rest'), (1.0, u'reordering'), (1.0, u'recharge'), (1.0, u'receiving'), (1.0, u'read'), (1.0, u'rag'), (1.0, u'question'), (1.0, u'purchases'), (1.0, u'pains'), (1.0, u'ordered'), (1.0, u'opened'), (1.0, u'one'), (1.0, u'none'), (1.0, u'first'), (1.0, u'ended'), (1.0, u'due'), (1.0, u'dead'), (1.0, u'dates'), (1.0, u'cost'), (1.0, u'confirmed'), (1.0, u'cleaned'), (1.0, u'children'), (1.0, u'checker'), (1.0, u'checked'), (1.0, u'cancelled'), (1.0, u'blistering'), (1.0, u'arrival'), (1.0, u'appears'), (1.0, u'answering')]\n"
     ]
    }
   ],
   "source": [
    "#computation for example in the poster\n",
    "# rl_list=[]\n",
    "# number_of_asins_on_which_keyword_separators_should_be_applied= 100\n",
    "# counter=0\n",
    "# rl_dict={}\n",
    "# TFIDF_dict={}\n",
    "# vec, map = TF_IDF_all(asin_dict)\n",
    "c = Rake()\n",
    "c.extract_keywords_from_text(pos_reviews_B00AZOOW6O)\n",
    "RAKE_pos_reviews_B00AZOOW6O= c.rank_list\n",
    "print RAKE_pos_reviews_B00AZOOW6O\n",
    "\n",
    "c = Rake()\n",
    "c.extract_keywords_from_text(neg_reviews_B00AZOOW6O)\n",
    "RAKE_neg_reviews_B00AZOOW6O= c.rank_list\n",
    "print RAKE_neg_reviews_B00AZOOW6O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Helper functions\n",
    "###########################\n",
    "\n",
    "# Generate frequency dictionary of all words in all reviews (needed for TF-IDF)\n",
    "def generateCorpus(X):\n",
    "    all_words = defaultdict(int)\n",
    "    for k in range(0,len(X)):\n",
    "\t\twordList = re.sub(\"[^\\w]\", \" \",  X[k]).split() # Clean and split data\n",
    "\t\tfor words in wordList:\n",
    "\t\t\tall_words[words.lower()] += 1\n",
    "    \n",
    "    return all_words\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t, 'n') for t in word_tokenize(doc)]\n",
    "\n",
    "def TF_IDF_all(asin_dict):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", analyzer='word', lowercase = True, tokenizer = LemmaTokenizer(), \n",
    "\t\t\t\t ngram_range=(1, 2), min_df = 2, max_df = 0.8)\n",
    "\n",
    "    vec = vectorizer.fit_transform(list(asin_dict.values()))\n",
    "    word_map=vectorizer.get_feature_names()\n",
    "\n",
    "    return vec, word_map\n",
    "\n",
    "def TF_IDF_asin(asin, asin_dict, vectorizer, word_map, n):\n",
    "    index = asin_dict.keys().index(asin)\n",
    "    tf = vectorizer[index]\n",
    "    \n",
    "    keywords = []\n",
    "    for col in tf.nonzero()[1]:\n",
    "        keywords.append((tf[0, col],word_map[col]))\n",
    "\n",
    "    sorted_keywords = sorted(keywords, key=lambda t: t[1] * -1)\n",
    "\n",
    "    return sorted_keywords[:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
