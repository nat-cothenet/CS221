{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CS221_11292018_0824 includes a RAKE class that applies RAKE on the input file\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "import collections\n",
    "import gzip\n",
    "import statistics as stat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data\n",
    "        \n",
    "#This block reads 5-core dataset\n",
    "# number_of_data_points_to_read= 10000 #Select number of data points to read\n",
    "counter= 0\n",
    "data=[]\n",
    "path= '/Users/srishti/Desktop/reviews_Health_and_Personal_Care_5.json'\n",
    "with open(path) as f:\n",
    "    for line in f:\n",
    "#         if counter <number_of_data_points_to_read:\n",
    "        data.append(json.loads(line))\n",
    "        counter+=1\n",
    "#         else: \n",
    "#             break\n",
    "\n",
    "X=[] #reivews\n",
    "Y=[] #ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_asins_to_select=110\n",
    "\n",
    "asin_mother_dict= collections.defaultdict(dict)\n",
    "asin_pos_reviews_dict = collections.defaultdict(list)\n",
    "temp_dict_all_parameters_known={}\n",
    "# counter= len(data)\n",
    "counter=0\n",
    "#Number of data_points_to_select\n",
    "number_of_data_points_to_select= len(data)\n",
    "for i in data:\n",
    "    if (len(asin_mother_dict.keys())< number_of_asins_to_select) or (i['asin'] in asin_mother_dict.keys()):\n",
    "        if i['asin'] not in asin_mother_dict.keys():\n",
    "            temp_dict={}\n",
    "            temp_dict['pos_reviews']=\"\"\n",
    "            temp_dict['neg_reviews']=\"\"\n",
    "            asin_mother_dict[i['asin']]=temp_dict\n",
    "            asin_pos_reviews_dict[i['asin']]= \"\" \n",
    "\n",
    "    #     asin_pos_reviews_dict[i['asin']].append(i['reviewText'])\n",
    "        if i['overall'] >= 4:\n",
    "            temp_dict={}\n",
    "            temp_dict['pos_reviews']= asin_mother_dict[i['asin']]['pos_reviews']+ \" \"+ i['reviewText']\n",
    "            asin_mother_dict[i['asin']].update(temp_dict) \n",
    "            asin_pos_reviews_dict[i['asin']]= asin_mother_dict[i['asin']]\n",
    "\n",
    "        else:\n",
    "            temp_dict={}\n",
    "            temp_dict['neg_reviews']= asin_mother_dict[i['asin']]['neg_reviews']+ \" \"+ i['reviewText']\n",
    "            asin_mother_dict[i['asin']].update(temp_dict) \n",
    "    #         asin_mother_dict[i['asin']]['neg_reviews'] = asin_mother_dict[i['asin']]['neg_reviews']+ \" \"+ i['reviewText']\n",
    "\n",
    "    for i in asin_mother_dict.keys():\n",
    "        if asin_mother_dict[i]['pos_reviews']==\"\":\n",
    "            asin_mother_dict[i]['all_param_known']='False'\n",
    "        else:\n",
    "            asin_mother_dict[i]['all_param_known']='True'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B0000533AY {'all_param_known': 'True', 'neg_reviews': u\" Do not waste your money.  This thermometer only measure 1/10 of a decimal point and it is such a pain to use.  It remembers your last temperature and displays that instead of taking your current temp when you turn it on.  There is only one blue button and I have yet to figure out how to make it start recording my temp - I push the blue button once and it shows yesterday's temp, hit it again and it flashes blank but nothin else happens.  The beeping while it records (when it finally starts!) is pretty quiet and I don't really mind that.  I just wish it worked consistently and actually measured the extra decimal point.  I've been using this to help diagnose hypothyroidism, but I would not recommend this thermometer for any purpose! Takes forever to get a temperature reading. I have found much better thermometers for less money at the local drugstore. I ordered the BD brand BBT and got this lavender colored Nexcare BBT model instead.  It's back lit which is quite nice in the dark in the morning.  I'm not sure it's all that accurate though -- sometimes I'll take my temp again right away to double check and it will be .2 to .3 off.  On my old BD brand which wasn't even a BBT, it was usually no more than .1 or .2 off if I redid it immediately.  The beeping is pretty quiet and doesn't bother me. Been using this every morning to try to track ovulation. Its quick and accurate (from what I can tell).My one complaint is it beeps the whole time its taking your temperature. If you are getting this for ovulating, you know that you have to take your temperature FIRST thing in the morning (preferably before you get out of bed). I wake up for work before my husband so I don't really want to be laying in bed while this thermometer beeps continuously and annoying the heck out of him... So I end up just taking my temperature in another room after I get up.. which makes it less accurate.So if it didn't do the annoying beeping I would have given 5 stars. For someone tracking ovulation, it really is a hindrance to have to get a less accurate reading just because the darn thing won't stop beeping. I used this every day for 3 months and then the battery died. I haven't replaced it yet because I can't find the right battery for it. The thermometer beeps the entire time you're taking your temperature, so I had to put my pillow over my head to not disturb my spouse. It's kind of annoying, but I love that there is a light on the display. It makes mornings easier. I found it to be accurate enough. This thermometer only shows 1/10 decimal, eg. 98.2, 97.7 instead of 98.22, 97.75. You cannot properly measure your BBT, Worthless. I think there are better options out there. I like that it's pink, and the back-light is helpful on dark mornings, but this thermometer makes this super annoying beep every time you use it - like every five seconds until it's finished. Though some reviewers here say you can put your thumb over the little hole where the sound comes out to dull it, that really doesn't solve the problem. It wakes my husband and my dog... THE GOOD:This is the only thermometer I have ever used to chart my cycles. It has always been accurate enough that I can clearly see when I have ovulated, so it definitely serves its purpose well. It is also great that it saves your temperature, which is a must have for me, especially since it doesn't light up when I'm done taking my temp, so I wouldn't be able to see it until I get up anyway.THE BAD:This thermometer is loud and annoying. It beeps the entire time you are taking your temperature. Within the first few times using it, I had to tape something over the speaker so that the beeps would at least be slightly muffled, but they are still loud even now. I like to doze while I'm taking my temperature, and I really don't see why all the beeping is necessary. Just one beep when I'm done would be fine. Also, the thermometer lights up before my temp is taken, but it doesn't light up to show me what my current temp is. What is the point of it lighting up at all? I got this one per the recommendation from my gyno. IT DIDN'T WORK! This would give me really off readings compared to my other basal thermometers and was totally abnormal for me.\", 'pos_reviews': u' This is a basic basal thermometer which I use for NFP. I found out about it from the book Taking Charge of Your Fertility - a system which I totally love and recommend for every girl/woman. This thermometer works well and quickly. I\\'ve been using it for a few months now with no issues whatsoever. It is a good quality thermometer - and it has even stood up to my toddler\\'s \"attention\" - when she finds it and presses the buttons a million times before I can intervene :)Very good product that can serve many purposes and definitely serves mine! It served its purpose and so far I haven\\'t had any problems. It seems as accurate as possible from what I can tell. My friend recommended I get one of these and I got the best one I could find on Amazon. This works great. It\\'s been really helpful so far! This is kind of loud, and if I play with the button too much in the dark, on a restart the temperature shown isn\\'t ALWAYS the last temperature it measured. But the product has lasted and I trust it more than the CVS brand I tried. The important thing is not to change brands midway through the same cycle.  I\\'d buy this again. I have learned where to cover the sound to help make it quieter. After reading many reviews and not wanting to spend a lot on a thermometer, I got this one to chart my temperature while I was trying to get pregnant.  That was 2.5 years ago.  I still use it and it works just fine.  Sometimes it\\'s hard to get the reading but you know if you have it in your mouth right because it will beep.  If you dont want to spend a lot on a thermometer dont hesitate to get this one! I just needed to replace my regular thermometer.  It works great.  The beeping is not loud as some reviews claim.  Works just fine for me. first timer doing the temp. charting but this lil thing has been SO handy! Easy to use even in the dark, and doesn\\'t take very long :D Accurate and fast, this is a great BBT. However, the beeps wake my husband up if he is sleeping next to me. I think I will need to put tape over the beeping mechanism. SUPER EASY TO USE. SAVES THE PREVIOUS TEMP JUST IN CASE YOU FORGET TO LOG IT. COMES WITH A NICE LITTLE COVER. GOOD BUY!! I\\'m very happy with this purchase. I\\'ve been using this thermometer almost every morning for about 2 weeks now and it seems consistent and accurate. The beeping sometimes seems loud since the device is right next to your head, but it\\'s never disturbed my husband or the baby who sleeps in our room. I opt to cover the little speaker hole with my finger to mute the beep even more.I like the constant beep so I know that it\\'s working and I have it positioned correctly.I think the best thing about this thermometer is how quick it is compared to regular thermometers I\\'ve used in the past. I don\\'t want to be stuck in bed for 3 extra minutes when I need to be cooking breakfast and getting the kids up. This thing is done in under a minute every time. I have used FAM to chart for close to 3 years now, and after a few months I ordered this digital Basal thermometer. I LOVE it. I use it every day and have only had to change the battery once so far, which is amazing.I take my temp at 6:30am every day, and usually go back to sleep. This thermometer beeps to indicate that it is in the correct position, and the beeping keeps me *just awake enough* that I don\\'t fall asleep and screw up temping. It can be a little louder than I (and my husband) would like, but I discovered that if I place my thumb over the back where the battery goes in, it muffles it a bit. My husband doesn\\'t even notice anymore, and I am never going to a different bbt thermometer if I can help it! I think that this is doing a great job. It\\'s my first time using a basal thermometer and I am doing everything like the instructions say. I am TTC so I really hope this is right. For the price, I have to say that I\\'d buy this again. Charting the temperatures taken by this thermometer clearly showed me which day I ovulated.  It was also clear which day my next cycle would start because of the drop in temperature.  I\\'m not sure how accurate the individual temperatures are though.  Every sample BBT chart I am able to find, including the one that comes with the thermometer, has 96.9 as the lowest possible temperature.  My pre-ovulation temp was usually lower than that (96.2 - 96.6).  The instructions state that you should have three consecutive hours of sleep before taking your waking temperature and I rarely sleep that well.  Perhaps this is the cause of my low temperatures.  I\\'ve also read that basal thermometers should measure hundredths and this one only measures tenths.  At any rate, my cycle has a clear trend so the themometer does its job.When you turn on the thermometer, a light comes on and the previous temperature that was taken and stored in memory is displayed.  The light then goes off and you can take your temperature.  The thermometer beeps while measuring your temp.  It usually beeps about ten to fifteen times for me and then a long beeping sound lets me know it is done.  At this point, you can press the button, the light comes on and your temperature is displayed.  The thermometer then turns off.  It will automatically turn off later if you forget.  The beeping does not wake my husband and since I take my temperature very early (around 4:30 AM when it is still dark), I find that the beeps help to keep me awake.'}\n",
      "B00004OCLT {'all_param_known': 'True', 'neg_reviews': '', 'pos_reviews': u' well designed scrub brush;easy on the hands I like my potatoes with the skins on. So, I always vigorously scrub wash the skins. I used to use the Scotch brand green/yellow scrubby sponges, but this works much better to actually clean down into all the little crevices. The size works perfect for me and the handle is easy to grip when wet. This brush has a wide rubber grip handle and firm bristles.  What makes it a bit unique is its size - at 11.1\" it is nearly a foot long.  You can use it to clean a large area where a smaller brush would make the job tedious, and in some instances to avoid bending as much due to its reach.The bristles are synthetic and fairly heavy gauge.  They can be used to clean corrosive acids and alkalis although this was made for use in bathrooms and kitchens.  I tested it on the shower floor and it\\'s perfect for that type of work.The instructions say this brush can be cleaned in the dishwasher.  With most brushes, the high heat of a dishwasher would cause bristles to fall out. How did I ever do with out this GREAT brush, I didn\\'t do well. I have a sink which is attached to the wall with 2 long posts holding it up in front of the sink. It is completely open underneath. It was very difficult to clean the tile on the wall behind the sink and even worse to clean the corner against the wall on the floor. That corner would really get dirty and the only way to clean it was to get on my knees snd reach.. My husband would have come to the rescue. Now all I have to do is bend because of the long handle..This brush cleaned the whole corner. Got into very crevice. Wiped the corner completely clean. It is fantastic to clean the indentation between the tiles on the wall and the tiles on the floor all around the bathroom floor. This cleans grout beautifully even though it is a very wide brush. It cleaned out all the dark grout between my old wall tiles where the grout was embedded in very narrow spaces..I did spray the tiles with Clorox Liquid Bathroom Disenfectant first.  The picture makes the brush look slim but that is misleading. The measurements are 11.1 long. The brush is 3.6 x 3.2 inches wide. Trust me, you will find many more uses than corners with this wonderful multi purpose cleaning tool. I actually bought this in a store but then couldn\\'t find the same one til I found it on Amazon.  It was one of the best dish cleaning brushes I\\'ve used--also works well on pots and pans.  I liked it so much that I ordered a second one to have on hand just in case they quit selling this one. the brush head and overall size of the tool was larger than I expected - but so much the better to clean something fast, right?  the colors of the tool appeal to me, I\\'m trying to psych myself up to clean more.  the brush didn\\'t seem too making my arm/ shoulder ache. I use this brush in the kitchen and love it. It is great for scrubbing dishes, pots and pans and also to scrub the sink out once the dishes are done. Another great OXO product I like this brush because the bristles are thick and have a convex shape to the brush to get in and dig out the grime.  The handle is solid, too. After getting this brush I thought the overall size of it might be a problem, but proved it wasn\\'t for the things I have used it on. One excellent job it does is cleaning a stainless steel sink. The bristles are long and stiffer making the task less tedious and using about half the time and elbow grease of the way I have been doing it. One thing that could be improved is the handle. It should be just a bit smaller around and have finger notches on the bottom for improved handling. That is the only reason I didn\\'t give it 5 stars. I usually buy Oxo - see my other reviews. This is a very good brush initially. We tried it on the bathroom shower stall corners - works okay... Hope this helps. Does what it says--gets in those hard to reach places like the corners of the tub, grout, etc. The handle is perfect. OXO always makes quality stuff and this is no exception. I actually got rid of the mildew in the corner (well, the bleach did) because I could actually get in there for once. I couldnt find a brush big enough for our tiled shower that would get the corners and this works great. Cant say enough about it I\\'ve dedicated this brush to shower maintenance, and another in the kitchen would probably be an equally good investment. Oxo brushes stand up really well and have just the right amount of stiffness to speed the work along.This brush cleans the shower stall with much less effort than previous methods, thanks to the large brush head and perfect grip and angle on the handle. It does the flat surfaces quickly and easily gets into the corners and crevices.Here\\'s a great tip I\\'ve learned after much experimentation. Clean your shower with a spray bottle filled with one cup of white vinegar and three cups of water - add a few drops of dish soap if you like. The vinegar retards mold and mildew very effectively, and it\\'s much easier on my nose than the chlorine bleach products I had been using.The same vinegar solution is great for water bottles, watch bands, and anything else that has a tendency to start smelling like an old dish rag. It\\'s cheap, it\\'s safe, and it\\'s effective. Wish I\\'d known about this a long time ago. Sturdy, easy to use handle, bristles have not broken off.  Great for edge cleaning but not over wide surface areas like walls.  Yup, it is truly a good corner and edges brush. This is an excellent shower brush.  I hang mine from my shower caddy where it\\'s ready for use.Gets into corners and the bristles are stiff enough to do a really good job. My male significant other cannot hit the oval bowl.  The tile floor must be scrubbed weekly.  This does the job without too much pressure on the joints!. I highly recommend this brush. Like all of Oxo products, it is well designed, easy to handle and does a superior job of household cleanup. I just finished brushing my screens and cleaning my screens and doorways and am happy that I purchased this brush. I use this brush to clean my tile grout. It gets into small spaces very well and the brush head is strong enough to clean the grooves in my shower grout line which is very narrow.'}\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for i in asin_mother_dict.keys():\n",
    "    if counter <2:\n",
    "        print i+ \" \"+ str(asin_mother_dict[i])\n",
    "        counter+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asin_mother_dict_copy= asin_mother_dict.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asin_mother_dict= asin_mother_dict_copy.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block reads meta data\n",
    "#reading meta data\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "meta_data = []\n",
    "# meta_path= '/Users/srishti/Desktop/meta_Books.json.gz'\n",
    "meta_path= '/Users/srishti/Desktop/meta_Health_and_Personal_Care.json.gz'\n",
    "counter= 1\n",
    "\n",
    "\n",
    "for line in parse(meta_path):\n",
    "    meta_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "asin_title_map = collections.defaultdict(list)\n",
    "all_asins_set= set(asin_mother_dict.keys())\n",
    "\n",
    "for i in meta_data:\n",
    "    temp_dict={}\n",
    "    temp_dict_all_parameters_known={}\n",
    "    if i['asin'] in all_asins_set:\n",
    "        all_asins_set.remove(i['asin'])\n",
    "        #Getting Titles\n",
    "        if 'title' in i.keys():\n",
    "            temp_dict['title']= i['title']\n",
    "#             print i['asin']\n",
    "#             print asin_mother_dict[i['asin']]\n",
    "            asin_mother_dict[i['asin']].update(temp_dict)\n",
    "    #         asin_title_map[i['asin']] = i['title']\n",
    "\n",
    "        else:\n",
    "            temp_dict['title']= None\n",
    "            temp_dict['all_param_known']='False'\n",
    "            asin_mother_dict[i['asin']].update(temp_dict)\n",
    "            asin_title_map[i['asin']] = None\n",
    "\n",
    "        #Adding also_bought, also_viewed, bought_together and buy_after_viewing\n",
    "        temp_dict={}\n",
    "        temp_dict_all_parameters_known={}\n",
    "        if 'related' in i.keys():\n",
    "            if 'also_bought' in i['related']:\n",
    "                temp_dict['also_bought']= i['related']['also_bought']\n",
    "            else:\n",
    "                temp_dict['also_bought']= None\n",
    "\n",
    "            if 'also_viewed' in i['related']:\n",
    "                temp_dict['also_viewed']= i['related']['also_viewed']\n",
    "            else:\n",
    "                temp_dict['also_viewed']= None\n",
    "\n",
    "            if 'bought_together' in i['related']:\n",
    "                temp_dict['bought_together']= i['related']['bought_together']\n",
    "            else:\n",
    "                temp_dict['bought_together']= None\n",
    "\n",
    "            if 'buy_after_viewing' in i['related']:\n",
    "                temp_dict['buy_after_viewing']= i['related']['buy_after_viewing']\n",
    "            else:\n",
    "                temp_dict['buy_after_viewing']= None\n",
    "\n",
    "            asin_mother_dict[i['asin']].update(temp_dict)\n",
    "        else:\n",
    "            temp_dict['all_param_known']='False'\n",
    "            temp_dict['also_viewed']= None\n",
    "            temp_dict['also_bought']= None\n",
    "            temp_dict['bought_together']= None\n",
    "            temp_dict['buy_after_viewing']= None\n",
    "\n",
    "            asin_mother_dict[i['asin']].update(temp_dict)\n",
    "\n",
    "        #Adding categories\n",
    "        #NOTE HEALTH & PERSONAL CARE IS A CATEGORY FOR ALL PRODUCT, NEED TO ADDRESS THAT\n",
    "        temp_dict={}\n",
    "        temp_dict_all_parameters_known={}\n",
    "        if 'categories' in i.keys():\n",
    "            temp_dict['categories']= i['categories'][0]\n",
    "            asin_mother_dict[i['asin']].update(temp_dict)\n",
    "        else:\n",
    "            temp_dict['categories']= None\n",
    "            temp_dict['all_param_known']='False'\n",
    "            asin_mother_dict[i['asin']].update(temp_dict)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B0000533AY\n",
      "{'buy_after_viewing': None, 'title': '3M Digital Basal Thermometer', 'pos_reviews': u' This is a basic basal thermometer which I use for NFP. I found out about it from the book Taking Charge of Your Fertility - a system which I totally love and recommend for every girl/woman. This thermometer works well and quickly. I\\'ve been using it for a few months now with no issues whatsoever. It is a good quality thermometer - and it has even stood up to my toddler\\'s \"attention\" - when she finds it and presses the buttons a million times before I can intervene :)Very good product that can serve many purposes and definitely serves mine! It served its purpose and so far I haven\\'t had any problems. It seems as accurate as possible from what I can tell. My friend recommended I get one of these and I got the best one I could find on Amazon. This works great. It\\'s been really helpful so far! This is kind of loud, and if I play with the button too much in the dark, on a restart the temperature shown isn\\'t ALWAYS the last temperature it measured. But the product has lasted and I trust it more than the CVS brand I tried. The important thing is not to change brands midway through the same cycle.  I\\'d buy this again. I have learned where to cover the sound to help make it quieter. After reading many reviews and not wanting to spend a lot on a thermometer, I got this one to chart my temperature while I was trying to get pregnant.  That was 2.5 years ago.  I still use it and it works just fine.  Sometimes it\\'s hard to get the reading but you know if you have it in your mouth right because it will beep.  If you dont want to spend a lot on a thermometer dont hesitate to get this one! I just needed to replace my regular thermometer.  It works great.  The beeping is not loud as some reviews claim.  Works just fine for me. first timer doing the temp. charting but this lil thing has been SO handy! Easy to use even in the dark, and doesn\\'t take very long :D Accurate and fast, this is a great BBT. However, the beeps wake my husband up if he is sleeping next to me. I think I will need to put tape over the beeping mechanism. SUPER EASY TO USE. SAVES THE PREVIOUS TEMP JUST IN CASE YOU FORGET TO LOG IT. COMES WITH A NICE LITTLE COVER. GOOD BUY!! I\\'m very happy with this purchase. I\\'ve been using this thermometer almost every morning for about 2 weeks now and it seems consistent and accurate. The beeping sometimes seems loud since the device is right next to your head, but it\\'s never disturbed my husband or the baby who sleeps in our room. I opt to cover the little speaker hole with my finger to mute the beep even more.I like the constant beep so I know that it\\'s working and I have it positioned correctly.I think the best thing about this thermometer is how quick it is compared to regular thermometers I\\'ve used in the past. I don\\'t want to be stuck in bed for 3 extra minutes when I need to be cooking breakfast and getting the kids up. This thing is done in under a minute every time. I have used FAM to chart for close to 3 years now, and after a few months I ordered this digital Basal thermometer. I LOVE it. I use it every day and have only had to change the battery once so far, which is amazing.I take my temp at 6:30am every day, and usually go back to sleep. This thermometer beeps to indicate that it is in the correct position, and the beeping keeps me *just awake enough* that I don\\'t fall asleep and screw up temping. It can be a little louder than I (and my husband) would like, but I discovered that if I place my thumb over the back where the battery goes in, it muffles it a bit. My husband doesn\\'t even notice anymore, and I am never going to a different bbt thermometer if I can help it! I think that this is doing a great job. It\\'s my first time using a basal thermometer and I am doing everything like the instructions say. I am TTC so I really hope this is right. For the price, I have to say that I\\'d buy this again. Charting the temperatures taken by this thermometer clearly showed me which day I ovulated.  It was also clear which day my next cycle would start because of the drop in temperature.  I\\'m not sure how accurate the individual temperatures are though.  Every sample BBT chart I am able to find, including the one that comes with the thermometer, has 96.9 as the lowest possible temperature.  My pre-ovulation temp was usually lower than that (96.2 - 96.6).  The instructions state that you should have three consecutive hours of sleep before taking your waking temperature and I rarely sleep that well.  Perhaps this is the cause of my low temperatures.  I\\'ve also read that basal thermometers should measure hundredths and this one only measures tenths.  At any rate, my cycle has a clear trend so the themometer does its job.When you turn on the thermometer, a light comes on and the previous temperature that was taken and stored in memory is displayed.  The light then goes off and you can take your temperature.  The thermometer beeps while measuring your temp.  It usually beeps about ten to fifteen times for me and then a long beeping sound lets me know it is done.  At this point, you can press the button, the light comes on and your temperature is displayed.  The thermometer then turns off.  It will automatically turn off later if you forget.  The beeping does not wake my husband and since I take my temperature very early (around 4:30 AM when it is still dark), I find that the beeps help to keep me awake.', 'also_bought': ['0060881909', 'B0026995KO', 'B002VLYAOI', 'B000052XHI', 'B00AOJ5R8W', 'B00ASGX4DQ', 'B004AOMAOG', 'B004IJHDN6', 'B00D05VGC8', 'B000S2O1CI', 'B001FYLNVU', 'B004HCLENY', 'B001E1Y1X6', 'B000E7VDKU', 'B002V0ZJ4Y', 'B004GHALRK', 'B0006SFQGO', 'B004G5RHCO', 'B005P0XLRO', 'B004RBL5ZM', 'B00AOJ5R64', 'B0002G2M9Y', 'B0006HDOSM', 'B005B3HH2A', '1451620705', 'B00DOJG6RA', '1623153077', 'B00IGAVIFM', '0060937645', 'B001E101L2', 'B0002YIQLY', 'B001OVFAA4', 'B0000532QB', '0316024503', 'B001FYGQ5I', 'B0053KMM94', 'B000X29GY6', 'B007N8FWB4', 'B009G4JCP0', '1561487171', 'B007VT30C8', 'B005H7RDJC', 'B00GUSJ3MC', 'B006F5BC7E', 'B000GQSMOE', 'B008AJPXKU', 'B00C76FUFU', 'B0009ETA6M', '0767926102', '096708976X', 'B009YLEL1K', 'B00D05VGCS', 'B009G497KK', 'B001R6K51K', 'B002CPRLH6', 'B001M0XKRC', 'B005GQQ96C', 'B003IP8BC8', 'B000052XHJ', 'B006F5BCLA', 'B00115BJ30', 'B000NDS2CC', '0761148574', 'B008VR5MBQ', 'B000O6YCZY', '0761142126', 'B002YR7A9Q', 'B0007SMLUM', 'B0027MFBKI', 'B00455TU7U', 'B0002YIQEQ', 'B004GCJML6', 'B007KDX64C', 'B005JAT3TU', 'B000F4WS6A', '0761152768', 'B001F1G6SI', 'B00AZHHSZI', 'B000N7G3P6', 'B0029O0BUE', 'B000EE8036', 'B003FBOMPK', 'B00CDL36JQ', 'B0009F3PP8', 'B00EMG3PLY', 'B003ALLHLM', 'B000F76ISG', '1455515485', 'B000JVA80C', 'B00CDKT3G2', 'B0062CW1BG', 'B003DGZRNS', 'B0045681S8', 'B0098U0QC0'], 'neg_reviews': u\" Do not waste your money.  This thermometer only measure 1/10 of a decimal point and it is such a pain to use.  It remembers your last temperature and displays that instead of taking your current temp when you turn it on.  There is only one blue button and I have yet to figure out how to make it start recording my temp - I push the blue button once and it shows yesterday's temp, hit it again and it flashes blank but nothin else happens.  The beeping while it records (when it finally starts!) is pretty quiet and I don't really mind that.  I just wish it worked consistently and actually measured the extra decimal point.  I've been using this to help diagnose hypothyroidism, but I would not recommend this thermometer for any purpose! Takes forever to get a temperature reading. I have found much better thermometers for less money at the local drugstore. I ordered the BD brand BBT and got this lavender colored Nexcare BBT model instead.  It's back lit which is quite nice in the dark in the morning.  I'm not sure it's all that accurate though -- sometimes I'll take my temp again right away to double check and it will be .2 to .3 off.  On my old BD brand which wasn't even a BBT, it was usually no more than .1 or .2 off if I redid it immediately.  The beeping is pretty quiet and doesn't bother me. Been using this every morning to try to track ovulation. Its quick and accurate (from what I can tell).My one complaint is it beeps the whole time its taking your temperature. If you are getting this for ovulating, you know that you have to take your temperature FIRST thing in the morning (preferably before you get out of bed). I wake up for work before my husband so I don't really want to be laying in bed while this thermometer beeps continuously and annoying the heck out of him... So I end up just taking my temperature in another room after I get up.. which makes it less accurate.So if it didn't do the annoying beeping I would have given 5 stars. For someone tracking ovulation, it really is a hindrance to have to get a less accurate reading just because the darn thing won't stop beeping. I used this every day for 3 months and then the battery died. I haven't replaced it yet because I can't find the right battery for it. The thermometer beeps the entire time you're taking your temperature, so I had to put my pillow over my head to not disturb my spouse. It's kind of annoying, but I love that there is a light on the display. It makes mornings easier. I found it to be accurate enough. This thermometer only shows 1/10 decimal, eg. 98.2, 97.7 instead of 98.22, 97.75. You cannot properly measure your BBT, Worthless. I think there are better options out there. I like that it's pink, and the back-light is helpful on dark mornings, but this thermometer makes this super annoying beep every time you use it - like every five seconds until it's finished. Though some reviewers here say you can put your thumb over the little hole where the sound comes out to dull it, that really doesn't solve the problem. It wakes my husband and my dog... THE GOOD:This is the only thermometer I have ever used to chart my cycles. It has always been accurate enough that I can clearly see when I have ovulated, so it definitely serves its purpose well. It is also great that it saves your temperature, which is a must have for me, especially since it doesn't light up when I'm done taking my temp, so I wouldn't be able to see it until I get up anyway.THE BAD:This thermometer is loud and annoying. It beeps the entire time you are taking your temperature. Within the first few times using it, I had to tape something over the speaker so that the beeps would at least be slightly muffled, but they are still loud even now. I like to doze while I'm taking my temperature, and I really don't see why all the beeping is necessary. Just one beep when I'm done would be fine. Also, the thermometer lights up before my temp is taken, but it doesn't light up to show me what my current temp is. What is the point of it lighting up at all? I got this one per the recommendation from my gyno. IT DIDN'T WORK! This would give me really off readings compared to my other basal thermometers and was totally abnormal for me.\", 'also_viewed': ['B000O6YCZY', 'B006F5BCLA', 'B009HONS4K', 'B00BR4BRXW', 'B003SLX2NU', 'B0017RZHYY', 'B00BIJSKRW', 'B000FQPVR6', 'B005X0TDSM', 'B000R8HI32', 'B004K4Q08I', 'B00D6N3HN0', 'B0013NB6CY', 'B0041OZ4HU', 'B00I0GZ4TS', 'B00CKL70LO', 'B000NIG65C', 'B000S2O1CI', '0060881909', 'B005QWV6S2', 'B00ISQCRZ4', 'B00DA1GDF2', 'B000LSY71Y', 'B0009HAZC2', 'B0070PITGK', 'B002VLYAOI', 'B0026995KO', 'B0000532QB', 'B003HLNLPA', 'B000088KGZ', 'B004W30L6O', 'B002PLD5PO', 'B001MWV11M', 'B000RY4ZFA', 'B001FYLNVU', 'B00AOJ5R8W', 'B004IJHDN6', 'B001E28YBK', 'B005H7RDJC', 'B00009B495', 'B0013NE0RC', 'B00EP1ZLO0', 'B003AGV8RU', 'B003SLPS5A', 'B00ASGX4DQ', 'B000E7VDKU', '0060937645'], 'bought_together': ['0060881909', 'B0026995KO'], 'all_param_known': 'True', 'categories': ['Health & Personal Care', 'Health Care', 'Thermometers', 'Basal Thermometers']}\n",
      "B00004OCLT\n",
      "{'buy_after_viewing': None, 'title': 'OXO Good Grips Corners and Edge Brush', 'pos_reviews': u' well designed scrub brush;easy on the hands I like my potatoes with the skins on. So, I always vigorously scrub wash the skins. I used to use the Scotch brand green/yellow scrubby sponges, but this works much better to actually clean down into all the little crevices. The size works perfect for me and the handle is easy to grip when wet. This brush has a wide rubber grip handle and firm bristles.  What makes it a bit unique is its size - at 11.1\" it is nearly a foot long.  You can use it to clean a large area where a smaller brush would make the job tedious, and in some instances to avoid bending as much due to its reach.The bristles are synthetic and fairly heavy gauge.  They can be used to clean corrosive acids and alkalis although this was made for use in bathrooms and kitchens.  I tested it on the shower floor and it\\'s perfect for that type of work.The instructions say this brush can be cleaned in the dishwasher.  With most brushes, the high heat of a dishwasher would cause bristles to fall out. How did I ever do with out this GREAT brush, I didn\\'t do well. I have a sink which is attached to the wall with 2 long posts holding it up in front of the sink. It is completely open underneath. It was very difficult to clean the tile on the wall behind the sink and even worse to clean the corner against the wall on the floor. That corner would really get dirty and the only way to clean it was to get on my knees snd reach.. My husband would have come to the rescue. Now all I have to do is bend because of the long handle..This brush cleaned the whole corner. Got into very crevice. Wiped the corner completely clean. It is fantastic to clean the indentation between the tiles on the wall and the tiles on the floor all around the bathroom floor. This cleans grout beautifully even though it is a very wide brush. It cleaned out all the dark grout between my old wall tiles where the grout was embedded in very narrow spaces..I did spray the tiles with Clorox Liquid Bathroom Disenfectant first.  The picture makes the brush look slim but that is misleading. The measurements are 11.1 long. The brush is 3.6 x 3.2 inches wide. Trust me, you will find many more uses than corners with this wonderful multi purpose cleaning tool. I actually bought this in a store but then couldn\\'t find the same one til I found it on Amazon.  It was one of the best dish cleaning brushes I\\'ve used--also works well on pots and pans.  I liked it so much that I ordered a second one to have on hand just in case they quit selling this one. the brush head and overall size of the tool was larger than I expected - but so much the better to clean something fast, right?  the colors of the tool appeal to me, I\\'m trying to psych myself up to clean more.  the brush didn\\'t seem too making my arm/ shoulder ache. I use this brush in the kitchen and love it. It is great for scrubbing dishes, pots and pans and also to scrub the sink out once the dishes are done. Another great OXO product I like this brush because the bristles are thick and have a convex shape to the brush to get in and dig out the grime.  The handle is solid, too. After getting this brush I thought the overall size of it might be a problem, but proved it wasn\\'t for the things I have used it on. One excellent job it does is cleaning a stainless steel sink. The bristles are long and stiffer making the task less tedious and using about half the time and elbow grease of the way I have been doing it. One thing that could be improved is the handle. It should be just a bit smaller around and have finger notches on the bottom for improved handling. That is the only reason I didn\\'t give it 5 stars. I usually buy Oxo - see my other reviews. This is a very good brush initially. We tried it on the bathroom shower stall corners - works okay... Hope this helps. Does what it says--gets in those hard to reach places like the corners of the tub, grout, etc. The handle is perfect. OXO always makes quality stuff and this is no exception. I actually got rid of the mildew in the corner (well, the bleach did) because I could actually get in there for once. I couldnt find a brush big enough for our tiled shower that would get the corners and this works great. Cant say enough about it I\\'ve dedicated this brush to shower maintenance, and another in the kitchen would probably be an equally good investment. Oxo brushes stand up really well and have just the right amount of stiffness to speed the work along.This brush cleans the shower stall with much less effort than previous methods, thanks to the large brush head and perfect grip and angle on the handle. It does the flat surfaces quickly and easily gets into the corners and crevices.Here\\'s a great tip I\\'ve learned after much experimentation. Clean your shower with a spray bottle filled with one cup of white vinegar and three cups of water - add a few drops of dish soap if you like. The vinegar retards mold and mildew very effectively, and it\\'s much easier on my nose than the chlorine bleach products I had been using.The same vinegar solution is great for water bottles, watch bands, and anything else that has a tendency to start smelling like an old dish rag. It\\'s cheap, it\\'s safe, and it\\'s effective. Wish I\\'d known about this a long time ago. Sturdy, easy to use handle, bristles have not broken off.  Great for edge cleaning but not over wide surface areas like walls.  Yup, it is truly a good corner and edges brush. This is an excellent shower brush.  I hang mine from my shower caddy where it\\'s ready for use.Gets into corners and the bristles are stiff enough to do a really good job. My male significant other cannot hit the oval bowl.  The tile floor must be scrubbed weekly.  This does the job without too much pressure on the joints!. I highly recommend this brush. Like all of Oxo products, it is well designed, easy to handle and does a superior job of household cleanup. I just finished brushing my screens and cleaning my screens and doorways and am happy that I purchased this brush. I use this brush to clean my tile grout. It gets into small spaces very well and the brush head is strong enough to clean the grooves in my shower grout line which is very narrow.', 'also_bought': ['B003M8GMS6', 'B00004OCL3', 'B00004OCLS', 'B00004OCLR', 'B00004OCIZ', 'B003KJ6KNO', 'B001O2WO4I', 'B0050B6CYW', 'B002BYI53C', 'B003JVE7FQ', 'B003KJ4YNM', 'B000CCDBRK', 'B002YLPL1Q', 'B00940DV3K', 'B000N454RC', 'B0009P68M0', 'B009W2FLOM', 'B00004OCLJ', 'B00940DUF4', 'B000HJ9A9Q', 'B00827PZE4', 'B003M8GMRW', 'B00940DV6W', 'B0087D1I44', 'B00021LQ0U', 'B002YLV7HS', 'B00004OCL2', 'B00940DVQ2', 'B006TK3X54', 'B008HMF9LS', 'B000NUV9XY', 'B0099WMWHO', 'B004I9EKAA', 'B0089XLLC6', 'B004BIKKCU', 'B002MV58JI', 'B008AUAK02', 'B000V72992', 'B00GBRO872', 'B00371VM0Q', 'B004I2EONK', 'B006H01IX0', 'B002YLRKH4', 'B000QRB26S', 'B00940DUH2', 'B0006ZVV02', 'B000N48MQW', 'B006RG0S8K', 'B00004OCLK', 'B005KDCMBM', 'B00940DUEK', 'B00CZA0Q6G', 'B00940DUE0', 'B00AJY515Q', 'B0043P0IAK', 'B002MV74WC', 'B00ANZHG7C', 'B000S8EQFO', 'B005FMZ40Y', 'B000HM84T0', 'B002BXOIOS', 'B004KSD65O', 'B0063IAJLS', 'B001339ZMW', 'B00HWNVEXK', 'B00940DV62', 'B0032JUZ1K', 'B0060LMSF8', 'B00940DUFY', 'B0038JE63W', 'B005ILL5IW', 'B009RXQSHA', 'B007UTM0AW', 'B002TLTXCE', 'B00008VXNE', 'B00CFALFXY', 'B0006V2RE0', 'B007G5ZV4C', 'B00467CCMC', 'B004C1UA5I', 'B000ILA3YY', 'B000QSKIEE', 'B0014COKYU', 'B0000DAPGS', 'B0002ITQHS', 'B007BOEI88', 'B004IR3044', 'B000FEDCNI', 'B000NBP3P8', 'B003I5HV06', 'B004ZLAGLS', 'B000EEZAZW', 'B004ZLAGJK', 'B0068PXFIA', 'B001D1O0KG', 'B00065W8F4', 'B000N46ZAC', 'B003RGO3ES', 'B009FUF6DM'], 'neg_reviews': '', 'also_viewed': ['B003M8GMS6', 'B00004OCL3', 'B00004OCLR', 'B00004OCIZ', 'B00004OCLS', 'B000N48MQW', 'B001O2WO4I', 'B0087D1I44', 'B002MV74WC', 'B002YLV7HS', 'B002YLPL1Q', 'B000N454RC', 'B0050B6CYW', 'B003JVE7FQ', 'B001QTVXK0', 'B00LMH0JOM', 'B002MV58JI', 'B00BE02HYC', 'B004BIKKCU', 'B002BYI53C', 'B000NUV9XY', 'B002YLX6CW', 'B00004OCL2', 'B0009ET65C', 'B00LIE7RZ8', 'B004ZXL0KM', 'B005ILL5IW', 'B005KDCLVI', 'B005FQ2804', 'B000CC91GK', 'B006H01IX0', 'B003M8GMRW', 'B001O2WO5W', 'B000HJ9A9Q', 'B00GBRO872', 'B003WZXVJC', 'B00G0T3CE6', 'B001795XQO', 'B00940DVQ2', 'B00940DUEK', 'B003KJ6KNO', 'B00004OCLJ', 'B004FTPT4E', 'B0068R8D44', 'B00004OCLH', 'B000N46ZAC', 'B00ASYHKN8', 'B00E81GOIO', 'B000ND7A5M', 'B0028LX8EY', 'B00004OCLK', 'B0087D1IGW', 'B008HMF9LS', 'B00167V9II', 'B004ZLAGJK', 'B002YLRKH4', 'B003I5HV06', 'B00IIVM2UE', 'B001SXV9C6', 'B00940DV62'], 'bought_together': ['B003M8GMS6', 'B00004OCL3'], 'all_param_known': 'True', 'categories': ['Health & Personal Care', 'Household Supplies', 'Cleaning Tools', 'Brushes']}\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in asin_mother_dict.keys():\n",
    "    if count < 2:\n",
    "        print i\n",
    "        print asin_mother_dict[i]\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin_mother_dict_copy= asin_mother_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n"
     ]
    }
   ],
   "source": [
    "for i in asin_mother_dict.keys():\n",
    "    if asin_mother_dict[i]['all_param_known']!= 'True':\n",
    "        del(asin_mother_dict[i])\n",
    "print len(asin_mother_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "embeddings_index = dict()\n",
    "f = open('/Users/srishti/Google Drive/000_7th Quarter/CS221/Project/untouched_data/glove.6B/glove.6B.50d.txt')\n",
    "for line in f:# first element of each line is the word and remaining elements are numerical represenation of each line \n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs# creates a dict of words and numerical representation of that word\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02648  ,  0.33737  ,  0.065667 , -0.11609  ,  0.41651  ,\n",
       "       -0.21142  , -0.69582  ,  0.2822   , -0.36077  , -0.13822  ,\n",
       "        0.012094 ,  0.086227 , -0.84638  ,  0.057195 ,  1.1582   ,\n",
       "        0.14703  , -0.0049197, -0.24899  , -0.96014  , -0.3038   ,\n",
       "        0.23972  ,  0.21058  ,  0.40608  ,  0.17789  ,  0.55253  ,\n",
       "       -1.6357   , -0.17784  , -0.45222  ,  0.45805  ,  0.14239  ,\n",
       "        3.7087   ,  0.40289  , -0.4083   , -0.29304  ,  0.030857 ,\n",
       "       -0.15361  ,  0.10607  ,  0.63397  ,  0.12397  , -0.25349  ,\n",
       "       -0.10344  ,  0.0069768, -0.17328  ,  0.35536  , -0.46369  ,\n",
       "        0.15285  ,  0.41475  , -0.3398   , -0.23043  ,  0.19069  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['dog']\n",
    "embeddings_index['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Implementation of Rapid Automatic Keyword Extraction algorithm.\n",
    "As described in the paper `Automatic keyword extraction from individual\n",
    "documents` by Stuart Rose, Dave Engel, Nick Cramer and Wendy Cowley.\n",
    "\"\"\"\n",
    "\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain, groupby, product\n",
    "\n",
    "import nltk\n",
    "from enum import Enum\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "\n",
    "class Metric(Enum):\n",
    "    \"\"\"Different metrics that can be used for ranking.\"\"\"\n",
    "\n",
    "    DEGREE_TO_FREQUENCY_RATIO = 0  # Uses d(w)/f(w) as the metric\n",
    "    WORD_DEGREE = 1  # Uses d(w) alone as the metric\n",
    "    WORD_FREQUENCY = 2  # Uses f(w) alone as the metric\n",
    "\n",
    "\n",
    "class Rake(object):\n",
    "    \"\"\"Rapid Automatic Keyword Extraction Algorithm.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        stopwords=None,\n",
    "        punctuations=None,\n",
    "        language=\"english\",\n",
    "        ranking_metric=Metric.DEGREE_TO_FREQUENCY_RATIO,\n",
    "        max_length=2,\n",
    "        min_length=1,\n",
    "    ):\n",
    "        \"\"\"Constructor.\n",
    "        :param stopwords: List of Words to be ignored for keyword extraction.\n",
    "        :param punctuations: Punctuations to be ignored for keyword extraction.\n",
    "        :param language: Language to be used for stopwords\n",
    "        :param max_length: Maximum limit on the number of words in a phrase\n",
    "                           (Inclusive. Defaults to 100000)\n",
    "        :param min_length: Minimum limit on the number of words in a phrase\n",
    "                           (Inclusive. Defaults to 1)\n",
    "        \"\"\"\n",
    "        # By default use degree to frequency ratio as the metric.\n",
    "        if isinstance(ranking_metric, Metric):\n",
    "            self.metric = ranking_metric\n",
    "        else:\n",
    "            self.metric = Metric.DEGREE_TO_FREQUENCY_RATIO\n",
    "\n",
    "        # If stopwords not provided we use language stopwords by default.\n",
    "        self.stopwords = stopwords\n",
    "        if self.stopwords is None:\n",
    "            self.stopwords = nltk.corpus.stopwords.words(language)\n",
    "\n",
    "        # If punctuations are not provided we ignore all punctuation symbols.\n",
    "        self.punctuations = punctuations\n",
    "        if self.punctuations is None:\n",
    "            self.punctuations = string.punctuation\n",
    "\n",
    "        # All things which act as sentence breaks during keyword extraction.\n",
    "        self.to_ignore = set(chain(self.stopwords, self.punctuations))\n",
    "\n",
    "        # Assign min or max length to the attributes\n",
    "        self.min_length = min_length\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Stuff to be extracted from the provided text.\n",
    "        self.frequency_dist = None\n",
    "        self.degree = None\n",
    "        self.rank_list = None\n",
    "        self.ranked_phrases = None\n",
    "\n",
    "    def extract_keywords_from_text(self, text):\n",
    "        \"\"\"Method to extract keywords from the text provided.\n",
    "        :param text: Text to extract keywords from, provided as a string.\n",
    "        \"\"\"\n",
    "        sentences = nltk.tokenize.sent_tokenize(text)\n",
    "        self.extract_keywords_from_sentences(sentences)\n",
    "\n",
    "    def extract_keywords_from_sentences(self, sentences):\n",
    "        \"\"\"Method to extract keywords from the list of sentences provided.\n",
    "        :param sentences: Text to extraxt keywords from, provided as a list\n",
    "                          of strings, where each string is a sentence.\n",
    "        \"\"\"\n",
    "        phrase_list = self._generate_phrases(sentences)\n",
    "        self._build_frequency_dist(phrase_list)\n",
    "        self._build_word_co_occurance_graph(phrase_list)\n",
    "        self._build_ranklist(phrase_list)\n",
    "\n",
    "    def get_ranked_phrases(self):\n",
    "        \"\"\"Method to fetch ranked keyword strings.\n",
    "        :return: List of strings where each string represents an extracted\n",
    "                 keyword string.\n",
    "        \"\"\"\n",
    "        return self.ranked_phrases\n",
    "\n",
    "    def get_ranked_phrases_with_scores(self):\n",
    "        \"\"\"Method to fetch ranked keyword strings along with their scores.\n",
    "        :return: List of tuples where each tuple is formed of an extracted\n",
    "                 keyword string and its score. Ex: (5.68, 'Four Scoures')\n",
    "        \"\"\"\n",
    "        return self.rank_list\n",
    "\n",
    "    def get_word_frequency_distribution(self):\n",
    "        \"\"\"Method to fetch the word frequency distribution in the given text.\n",
    "        :return: Dictionary (defaultdict) of the format `word -> frequency`.\n",
    "        \"\"\"\n",
    "        return self.frequency_dist\n",
    "\n",
    "    def get_word_degrees(self):\n",
    "        \"\"\"Method to fetch the degree of words in the given text. Degree can be\n",
    "        defined as sum of co-occurances of the word with other words in the\n",
    "        given text.\n",
    "        :return: Dictionary (defaultdict) of the format `word -> degree`.\n",
    "        \"\"\"\n",
    "        return self.degree\n",
    "\n",
    "    def _build_frequency_dist(self, phrase_list):\n",
    "        \"\"\"Builds frequency distribution of the words in the given body of text.\n",
    "        :param phrase_list: List of List of strings where each sublist is a\n",
    "                            collection of words which form a contender phrase.\n",
    "        \"\"\"\n",
    "        self.frequency_dist = Counter(chain.from_iterable(phrase_list))\n",
    "\n",
    "    def _build_word_co_occurance_graph(self, phrase_list):\n",
    "        \"\"\"Builds the co-occurance graph of words in the given body of text to\n",
    "        compute degree of each word.\n",
    "        :param phrase_list: List of List of strings where each sublist is a\n",
    "                            collection of words which form a contender phrase.\n",
    "        \"\"\"\n",
    "        co_occurance_graph = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        for phrase in phrase_list:\n",
    "            # For each phrase in the phrase list, count co-occurances of the\n",
    "            # word with other words in the phrase.\n",
    "            #\n",
    "            # Note: Keep the co-occurances graph as is, to help facilitate its\n",
    "            # use in other creative ways if required later.\n",
    "            for (word, coword) in product(phrase, phrase):\n",
    "                co_occurance_graph[word][coword] += 1\n",
    "        self.degree = defaultdict(lambda: 0)\n",
    "        for key in co_occurance_graph:\n",
    "            self.degree[key] = sum(co_occurance_graph[key].values())\n",
    "\n",
    "    def _build_ranklist(self, phrase_list):\n",
    "        \"\"\"Method to rank each contender phrase using the formula\n",
    "              phrase_score = sum of scores of words in the phrase.\n",
    "              word_score = d(w)/f(w) where d is degree and f is frequency.\n",
    "        :param phrase_list: List of List of strings where each sublist is a\n",
    "                            collection of words which form a contender phrase.\n",
    "        \"\"\"\n",
    "        self.rank_list = []\n",
    "        for phrase in phrase_list:\n",
    "            rank = 0.0\n",
    "            for word in phrase:\n",
    "                if self.metric == Metric.DEGREE_TO_FREQUENCY_RATIO:\n",
    "                    rank += 1.0 * self.degree[word] / self.frequency_dist[word]\n",
    "                elif self.metric == Metric.WORD_DEGREE:\n",
    "                    rank += 1.0 * self.degree[word]\n",
    "                else:\n",
    "                    rank += 1.0 * self.frequency_dist[word]\n",
    "            self.rank_list.append((rank, \" \".join(phrase)))\n",
    "        self.rank_list.sort(reverse=True)\n",
    "        self.ranked_phrases = [ph[1] for ph in self.rank_list]\n",
    "\n",
    "    def _generate_phrases(self, sentences):\n",
    "        \"\"\"Method to generate contender phrases given the sentences of the text\n",
    "        document.\n",
    "        :param sentences: List of strings where each string represents a\n",
    "                          sentence which forms the text.\n",
    "        :return: Set of string tuples where each tuple is a collection\n",
    "                 of words forming a contender phrase.\n",
    "        \"\"\"\n",
    "        phrase_list = set()\n",
    "        # Create contender phrases from sentences.\n",
    "        for sentence in sentences:\n",
    "            word_list = [word.lower() for word in wordpunct_tokenize(sentence)]\n",
    "            phrase_list.update(self._get_phrase_list_from_words(word_list))\n",
    "        return phrase_list\n",
    "\n",
    "    def _get_phrase_list_from_words(self, word_list):\n",
    "        \"\"\"Method to create contender phrases from the list of words that form\n",
    "        a sentence by dropping stopwords and punctuations and grouping the left\n",
    "        words into phrases. Only phrases in the given length range (both limits\n",
    "        inclusive) would be considered to build co-occurrence matrix. Ex:\n",
    "        Sentence: Red apples, are good in flavour.\n",
    "        List of words: ['red', 'apples', \",\", 'are', 'good', 'in', 'flavour']\n",
    "        List after dropping punctuations and stopwords.\n",
    "        List of words: ['red', 'apples', *, *, good, *, 'flavour']\n",
    "        List of phrases: [('red', 'apples'), ('good',), ('flavour',)]\n",
    "        List of phrases with a correct length:\n",
    "        For the range [1, 2]: [('red', 'apples'), ('good',), ('flavour',)]\n",
    "        For the range [1, 1]: [('good',), ('flavour',)]\n",
    "        For the range [2, 2]: [('red', 'apples')]\n",
    "        :param word_list: List of words which form a sentence when joined in\n",
    "                          the same order.\n",
    "        :return: List of contender phrases that are formed after dropping\n",
    "                 stopwords and punctuations.\n",
    "        \"\"\"\n",
    "        groups = groupby(word_list, lambda x: x not in self.to_ignore)\n",
    "        phrases = [tuple(group[1]) for group in groups if group[0]]\n",
    "        return list(\n",
    "            filter(\n",
    "                lambda x: self.min_length <= len(x) <= self.max_length, phrases\n",
    "            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Helper functions\n",
    "###########################\n",
    "\n",
    "# Generate frequency dictionary of all words in all reviews (needed for TF-IDF)\n",
    "def generateCorpus(X):\n",
    "    all_words = defaultdict(int)\n",
    "    for k in range(0,len(X)):\n",
    "\t\twordList = re.sub(\"[^\\w]\", \" \",  X[k]).split() # Clean and split data\n",
    "\t\tfor words in wordList:\n",
    "\t\t\tall_words[words.lower()] += 1\n",
    "    \n",
    "    return all_words\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t, 'n') for t in word_tokenize(doc)]\n",
    "\n",
    "def TF_IDF_all(asin_dict):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", analyzer='word', lowercase = True, tokenizer = LemmaTokenizer(), \n",
    "\t\t\t\t ngram_range=(1, 2), min_df = 2, max_df = 0.8)\n",
    "\n",
    "    vec = vectorizer.fit_transform(list(asin_dict.values()))\n",
    "    word_map=vectorizer.get_feature_names()\n",
    "\n",
    "    return vec, word_map\n",
    "\n",
    "def TF_IDF_asin(asin, asin_dict, vectorizer, word_map):\n",
    "    index = asin_dict.keys().index(asin)\n",
    "    tf = vectorizer[index]\n",
    "    \n",
    "    keywords = []\n",
    "    for col in tf.nonzero()[1]:\n",
    "        keywords.append((tf[0, col],word_map[col]))\n",
    "\n",
    "    sorted_keywords = sorted(keywords, key=lambda t: t[1] * -1)\n",
    "\n",
    "    return sorted_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n",
      "<type 'dict'>\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in asin_mother_dict.keys():\n",
    "    if count< 2:\n",
    "#         print asin_mother_dict[i]['pos_reviews']\n",
    "        print type (asin_mother_dict[i])\n",
    "#         print type (asin_mother_dict[i])\n",
    "        count+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin_dict= {}\n",
    "for i in asin_mother_dict.keys():\n",
    "#     print type(asin_mother_dict[i])\n",
    "#     print (asin_mother_dict[i]['pos_reviews'])\n",
    "    if asin_mother_dict[i]['all_param_known']=='True' :\n",
    "        asin_dict[i]= asin_mother_dict[i]['pos_reviews']\n",
    "\n",
    "number_of_asins_on_which_keyword_separators_should_be_applied= len(asin_dict.keys())\n",
    "counter=0\n",
    "rake_keywords_dict={}\n",
    "TFIDF_keywords_dict={}\n",
    "vec, map = TF_IDF_all(asin_dict)\n",
    "\n",
    "for i in asin_dict.keys():\n",
    "    if counter < number_of_asins_on_which_keyword_separators_should_be_applied:\n",
    "#         print asin_dict[i]\n",
    "        c = Rake()\n",
    "        c.extract_keywords_from_text(asin_dict[i])\n",
    "        rake_keywords_dict[i]= c.rank_list\n",
    "        counter+=1\n",
    "        \n",
    "        ###########################\n",
    "        # Run TF-IDF\n",
    "        ###########################\n",
    "#         #test_list = [0, 2, 3, 4, 8, 9, 12, 13, 14]\n",
    "#         test_list = [0]\n",
    "\n",
    "#         for i in test_list:\n",
    "#             my_asin = asin_dict.keys()[i]\n",
    "#             print my_asin\n",
    "#         print asin_title_map[i]\n",
    "\n",
    "        TFIDF_keywords_dict[i] = TF_IDF_asin(i, asin_dict, vec, map)\n",
    "#             print keywords\n",
    "    else:\n",
    "        break\n",
    "        #     rl_list.append(c.rank_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n"
     ]
    }
   ],
   "source": [
    "# d = Rake()\n",
    "# d.extract_keywords_from_text('I love cats and cats')\n",
    "# print d.rank_list\n",
    "# print d.ranked_phrases\n",
    "print len(TFIDF_keywords_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srishti/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:33: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/Users/srishti/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:36: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srishti/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:75: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/Users/srishti/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:89: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/Users/srishti/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:47: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srishti/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:78: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#converts reviews to embedding dict where key is the ASIN of a book\n",
    "count=0\n",
    "RAKE_review_dict={}\n",
    "TFIDF_review_dict={}\n",
    "\n",
    "lower_cutoff_for_word_to_be_considered=1#model parameter\n",
    "TFIDF_lower_cutoff_for_word_to_be_considered=0.0#model parameter\n",
    "\n",
    "number_of_reviews_for_clustering=100#select how many reviews are being used for clustering, small number reduces computation time. \n",
    "\n",
    "max_word_per_review= 20#model parameter\n",
    "TFIDF_max_word_per_review= max_word_per_review#model parameter\n",
    "\n",
    "\n",
    "if number_of_reviews_for_clustering > len(rake_keywords_dict.keys()):\n",
    "    print (\"number_of_reviews_for_clustering too large!!\")\n",
    "    print(\"number of reviews= \" + str(len(rake_keywords_dict.keys()))+ \" requested \" + str(number_of_reviews_for_clustering))\n",
    "else:\n",
    "    for i in rake_keywords_dict.keys():\n",
    "        normalization_factor=0\n",
    "#         print i\n",
    "        if count< number_of_reviews_for_clustering :\n",
    "            print count\n",
    "            count +=1\n",
    "    #         print rake_keywords_dict[i]\n",
    "            count_of_words_used=0\n",
    "#             print \"entering RAKE\"\n",
    "            for j in rake_keywords_dict[i]:\n",
    "#                 print \"entered RAKE\"\n",
    "                if count_of_words_used < max_word_per_review:\n",
    "                    count_of_words_used+=1\n",
    "                    if j[0] > lower_cutoff_for_word_to_be_considered:\n",
    "                        if j[1] not in embeddings_index.keys():\n",
    "                            for k in j[1].split():\n",
    "                #                 print (\"k=\" + k)\n",
    "                                if k in embeddings_index.keys():\n",
    "                                    if i not in RAKE_review_dict.keys():\n",
    "\n",
    "                                        RAKE_review_dict[i]= j[0]* embeddings_index[k] \n",
    "                                        normalization_factor+=1\n",
    "                                    else:\n",
    "                                        RAKE_review_dict[i]+= j[0]* embeddings_index[k] \n",
    "                                        normalization_factor+=1\n",
    "        #                         else:\n",
    "        #                             print k\n",
    "                        else:\n",
    "                            if j[1] in embeddings_index.keys():\n",
    "                #                 print (\"j=\" + j[1])\n",
    "                    #             RAKE_review_dict[i]+= rl_list[j][0]* embeddings_index[j][1]\n",
    "                                if i not in RAKE_review_dict.keys():\n",
    "                                    RAKE_review_dict[i]= j[0]* embeddings_index[j[1]]\n",
    "                                    normalization_factor+=1\n",
    "                                else:\n",
    "                                    RAKE_review_dict[i]+= j[0]* embeddings_index[j[1]]\n",
    "                                    normalization_factor+=1\n",
    "        #                     else:\n",
    "        #                         print j[1]\n",
    "#             print (\"entering normalization\" + str(i))\n",
    "            if normalization_factor >0:\n",
    "#                     RAKE_review_dict[i]= RAKE_review_dict[i]/ normalization_factor\n",
    "                [z/normalization_factor for z in RAKE_review_dict[i]]\n",
    "#             print (\"RAKE done..\")\n",
    "\n",
    "    #TF-IDF converts reviews to embedding dict where key is the ASIN of a book\n",
    "#             print (\"RAKE done..\")\n",
    "            TFIDF_normalization_factor=0\n",
    "            TFIDF_count_of_words_used=0\n",
    "#             print TFIDF_keywords_dict[i]\n",
    "#             print \"entering TFIDF\"\n",
    "            for j in TFIDF_keywords_dict[i]:\n",
    "                \n",
    "                if TFIDF_count_of_words_used < max_word_per_review:\n",
    "                    TFIDF_count_of_words_used+=1\n",
    "                    if j[0] > TFIDF_lower_cutoff_for_word_to_be_considered:\n",
    "                        if j[1] not in embeddings_index.keys():\n",
    "                            for k in j[1].split():\n",
    "#                                 print (\"k=\" + k)\n",
    "                                if k in embeddings_index.keys():\n",
    "#                                     print (\"k=\" + k)\n",
    "                                    if i not in TFIDF_review_dict.keys():\n",
    "                                        TFIDF_review_dict[i]= j[0]* embeddings_index[k] \n",
    "                                        TFIDF_normalization_factor+=1\n",
    "                                    else:\n",
    "                                        TFIDF_review_dict[i]+= j[0]* embeddings_index[k] \n",
    "                                        TFIDF_normalization_factor+=1\n",
    "        #                         else:\n",
    "        #                             print k\n",
    "                        else:\n",
    "                            if j[1] in embeddings_index.keys():\n",
    "#                                 print (\"j=\" + j[1])\n",
    "                                if i not in TFIDF_review_dict.keys():\n",
    "                                    TFIDF_review_dict[i]= j[0]* embeddings_index[j[1]]\n",
    "                                    TFIDF_normalization_factor+=1\n",
    "                                else:\n",
    "                                    TFIDF_review_dict[i]+= j[0]* embeddings_index[j[1]]\n",
    "                                    TFIDF_normalization_factor+=1\n",
    "        #                     else:\n",
    "        #                         print j[1]\n",
    "#             print (\"entering TFIDF Normalization\" + str(i))\n",
    "#             print TFIDF_review_dict\n",
    "            if TFIDF_normalization_factor >0:\n",
    "#                     RAKE_review_dict[i]= RAKE_review_dict[i]/ normalization_factor\n",
    "                [z/TFIDF_normalization_factor for z in TFIDF_review_dict[i]]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print len(TFIDF_review_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count =0\n",
    "# for i in RAKE_review_dict.keys():\n",
    "#     if i not in TFIDF_review_dict.keys():\n",
    "#         print i\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAKE_review_dict_list=[]\n",
    "TFIDF_review_dict_list=[]\n",
    "for i in RAKE_review_dict.keys():\n",
    "    RAKE_review_dict_list.append(RAKE_review_dict[i])\n",
    "    TFIDF_review_dict_list.append(TFIDF_review_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 4 6 6 4 2 6 7 3 3 1 8 4 9 6 1 7 7 6 6 1 8 8 8 6 9 6 3 1 8 5 3 3 6 6 1 0\n",
      " 8 9 3 4 3 0 6 6 6 1 6 6 3 2 3 7 6 7 7 7 3 9 3 2 7 3 3 3 9 8 6 3 5 0 9 1 1\n",
      " 4 6 8 3 5 5 4 8 4 3 8 4 2 6 9 6 6 6 9 5 6 3 0 1 3 8]\n",
      "[1 2 2 2 6 9 2 2 7 2 2 6 2 2 8 9 2 7 7 6 8 8 2 2 6 2 3 0 2 0 3 2 7 2 8 3 2\n",
      " 2 7 2 8 9 2 7 2 6 2 3 2 2 2 0 2 2 2 2 6 0 7 6 6 2 6 2 7 2 6 2 9 4 2 2 2 7\n",
      " 2 2 7 7 3 5 0 3 2 2 7 7 7 8 0 2 8 7 8 6 1 6 2 2 6 2]\n"
     ]
    }
   ],
   "source": [
    "#holy K-means\n",
    "from sklearn.cluster import KMeans\n",
    "number_of_clusters= 10\n",
    "kmeans_random_state=0\n",
    "RAKE_kmeans = KMeans(n_clusters=number_of_clusters, random_state=kmeans_random_state).fit_predict(RAKE_review_dict_list)\n",
    "TFIDF_kmeans= KMeans(n_clusters=number_of_clusters, random_state=kmeans_random_state).fit_predict(TFIDF_review_dict_list)\n",
    "print RAKE_kmeans\n",
    "print TFIDF_kmeans\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAKE_Clustered Titles\n",
      "TFIDF_Clustered Titles\n"
     ]
    }
   ],
   "source": [
    "#matches the embeddings of review to a title\n",
    "RAKE_clusteredTitles= collections.defaultdict(list)\n",
    "RAKE_clustered_asins= collections.defaultdict(list)\n",
    "for i in range(0, len(RAKE_kmeans)):\n",
    "    for asin_value, word2VecList in RAKE_review_dict.items():\n",
    "        if (word2VecList == RAKE_review_dict_list[i]).all():\n",
    "#             print asin_value\n",
    "            RAKE_clusteredTitles[RAKE_kmeans[i]].append(asin_mother_dict[asin_value]['title'])\n",
    "#             temp_dict={}\n",
    "#             temp_dict['asins']= RAKE_clustered_asins[RAKE_kmeans[i]].append(asin_value)\n",
    "            RAKE_clustered_asins[RAKE_kmeans[i]].append(asin_value)\n",
    "            break\n",
    "print (\"RAKE_Clustered Titles\")\n",
    "# print clusteredTitles\n",
    "\n",
    "TFIDF_clusteredTitles= collections.defaultdict(list)\n",
    "TFIDF_clustered_asins= collections.defaultdict(list)\n",
    "for i in range(0, len(TFIDF_kmeans)):\n",
    "    for asin_value, word2VecList in TFIDF_review_dict.items():\n",
    "        if (word2VecList == TFIDF_review_dict_list[i]).all():\n",
    "#             print asin_value\n",
    "            TFIDF_clusteredTitles[TFIDF_kmeans[i]].append(asin_mother_dict[asin_value]['title'])\n",
    "            TFIDF_clustered_asins[TFIDF_kmeans[i]].append(asin_value)\n",
    "            break\n",
    "print (\"TFIDF_Clustered Titles\")\n",
    "# print TFIDF_clusteredTitles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print RAKE_clusteredTitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOutputDicts(clustered_asins_dict):\n",
    "#Create output dicts\n",
    "    output_dict={}\n",
    "    for i in clustered_asins_dict.keys():\n",
    "        temp_dict={}\n",
    "        temp_dict['asins']= clustered_asins_dict[i]\n",
    "        output_dict[i]= temp_dict\n",
    "    return output_dict\n",
    "    # print RAKE_output_dict\n",
    "\n",
    "# TFIDF_output_dict={}\n",
    "# for i in TFIDF_clustered_asins.keys():\n",
    "#     temp_dict={}\n",
    "#     temp_dict['asins']= TFIDF_clustered_asins[i]\n",
    "#     TFIDF_output_dict[i]= temp_dict\n",
    "# print TFIDF_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAKE_partial_output_dict= createOutputDicts(RAKE_clustered_asins)\n",
    "TFIDF_partial_output_dict=createOutputDicts(TFIDF_clustered_asins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'asins': [u'B000056OWW', u'B00005NAXK', u'B000052X7B', u'B000066CKV']}, 1: {'asins': [u'B000068PBT', u'B00000J47L', u'B000052Y44', u'B000052YHS', u'B0000530JF', u'B00004OCL3', u'B00000JHQ6', u'B00005R19P', u'B00005T3EH']}, 2: {'asins': [u'B000068PBL', u'B000067E30', u'B000066OC7', u'B000069J4X']}, 3: {'asins': [u'3812028492', u'B000068PBJ', u'B000052YHR', u'B0000531E2', u'B000053UOC', u'B00004YK10', u'B00006AMSM', u'B00004SRAX', u'B00004YK0Y', u'B00005339L', u'B000050B6B', u'B000052YA2', u'B000052XC6', u'B00005380N', u'B000066PGS', u'B00004T7UJ', u'B00006BSXM', u'B00005T3E3', u'B00005Q50D']}, 4: {'asins': [u'B00004OCLT', u'B00004OCLS', u'B00006G9LZ', u'B000052WNY', u'B000052YBV', u'B00004Z4AE', u'B000065CIL', u'B0000530SD']}, 5: {'asins': [u'B000060NUH', u'B00000JHQ2', u'B000052YBA', u'B00005RL5E', u'B0000532GM']}, 6: {'asins': [u'B000052WWV', u'B00004OCLR', u'B0000537JP', u'B0000537JG', u'B0000645VY', u'B000052XUV', u'B00005AUID', u'B000052XUG', u'B000052YFJ', u'B000052XFF', u'B0000532YB', u'B00005BJ92', u'B000062WUY', u'B000050B6Z', u'B000052XMR', u'B000052YOH', u'B000050AUB', u'B000052Y69', u'B00005NFBC', u'B0000532SD', u'B000050FF4', u'B00005BAWO', u'B00005UMZS']}, 7: {'asins': [u'B0000532RD', u'B00004YK1B', u'B00004YK1A', u'B0000536V6', u'B0000536V8', u'B000050B6D', u'B00005KGUB', u'B000052XC0']}, 8: {'asins': [u'B0000533AY', u'B0000635YY', u'B0000537YG', u'B00005JTW4', u'B0000537JQ', u'B000052WN3', u'B000052YFO', u'B0000537A5', u'B00000J9DU', u'B0000530YM', u'B000052XB5', u'B00005MOU9']}, 9: {'asins': [u'B00004OCLJ', u'B00005AUIE', u'B0000533I2', u'B000052YOB', u'B000053072', u'B0000691JH', u'B000050FF0', u'B000052YCG']}}\n",
      "{0: {'asins': [u'B000052YHR', u'B000052WN3', u'B00004YK0Y', u'B00005339L', u'B00004Z4AE', u'B000050FF0']}, 1: {'asins': [u'B0000533AY', u'B00005UMZS']}, 2: {'asins': [u'B00004OCLT', u'B000052WWV', u'B00004OCLR', u'B0000537JP', u'B0000532RD', u'B000068PBJ', u'B000068PBT', u'B00006G9LZ', u'B00004OCLJ', u'B00004YK1B', u'B00005JTW4', u'B0000537JQ', u'B00005AUIE', u'B000052YHS', u'B0000531E2', u'B000052YFJ', u'B000056OWW', u'B000052YFO', u'B00004YK10', u'B00005NAXK', u'B00005BJ92', u'B00004OCL3', u'B000052XMR', u'B00004SRAX', u'B000067E30', u'B0000536V6', u'B000052YOH', u'B0000536V8', u'B000050B6D', u'B000052XC0', u'B000052XC6', u'B000053072', u'B000050AUB', u'B000052X7B', u'B0000691JH', u'B00000JHQ6', u'B000052YBV', u'B000052Y69', u'B000065CIL', u'B00006BSXM', u'B0000532SD', u'B000066CKV', u'B00005T3EH', u'B00005MOU9']}, 3: {'asins': [u'B000052XUG', u'B000060NUH', u'B0000530JF', u'B000050B6Z', u'B000052YBA', u'B0000530YM']}, 4: {'asins': [u'B00000JHQ2']}, 5: {'asins': [u'B00005RL5E']}, 6: {'asins': [u'B00004OCLS', u'B0000635YY', u'B000052XUV', u'B00005AUID', u'B000062WUY', u'B00005KGUB', u'B000050B6B', u'B000066OC7', u'B000052YA2', u'B0000537A5', u'B0000532GM', u'B00005T3E3', u'B00005Q50D']}, 7: {'asins': [u'3812028492', u'B00004YK1A', u'B0000645VY', u'B000053UOC', u'B0000533I2', u'B0000532YB', u'B000052YOB', u'B00005380N', u'B00005R19P', u'B00000J9DU', u'B00004T7UJ', u'B000052XB5', u'B0000530SD', u'B000069J4X', u'B00005BAWO']}, 8: {'asins': [u'B0000537JG', u'B000052Y44', u'B0000537YG', u'B000052XFF', u'B000052WNY', u'B00005NFBC', u'B000050FF4', u'B000052YCG']}, 9: {'asins': [u'B000068PBL', u'B00000J47L', u'B00006AMSM', u'B000066PGS']}}\n"
     ]
    }
   ],
   "source": [
    "print RAKE_partial_output_dict\n",
    "print TFIDF_partial_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergetwolists(a,b):\n",
    "    c=a\n",
    "    for i in b:\n",
    "        if i not in a:\n",
    "            c.append(i)\n",
    "            \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=['1', '6', 'g']\n",
    "# b=['e', '7', '6']\n",
    "\n",
    "# merged_list=mergetwolists(a,b)\n",
    "# print merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateOutputDict(output_dict, mother_dict):\n",
    "#     output_dict_copy= output_dict.copy()\n",
    "    for i in output_dict:\n",
    "#         print i\n",
    "        temp_dict={}\n",
    "        temp_dict['also_viewed']=[]\n",
    "        temp_dict['also_bought']=[]\n",
    "        temp_dict['bought_together']=[]\n",
    "        temp_dict['buy_after_viewing']=[]\n",
    "        \n",
    "        for j in output_dict[i]['asins']:\n",
    "#             print j\n",
    "            if mother_dict[j]['also_viewed'] != None:\n",
    "                if 'also_viewed' in temp_dict.keys():\n",
    "                    temp_dict['also_viewed']=mergetwolists(temp_dict['also_viewed'], mother_dict[j]['also_viewed'])\n",
    "                else:\n",
    "                    temp_dict['also_viewed']= mother_dict[j]['also_viewed']\n",
    "                    \n",
    "            if mother_dict[j]['also_bought'] != None:\n",
    "                if 'also_bought' in temp_dict.keys():\n",
    "                    temp_dict['also_bought']=mergetwolists(temp_dict['also_bought'], mother_dict[j]['also_bought'])\n",
    "                else:\n",
    "                    temp_dict['also_bought']= mother_dict[j]['also_bought']\n",
    "\n",
    "            if mother_dict[j]['bought_together'] != None:\n",
    "                if 'bought_together' in temp_dict.keys():\n",
    "                    temp_dict['bought_together']=mergetwolists(temp_dict['bought_together'], mother_dict[j]['bought_together'])\n",
    "                else:\n",
    "                    temp_dict['bought_together']= mother_dict[j]['bought_together']\n",
    "            \n",
    "            if mother_dict[j]['buy_after_viewing'] != None:\n",
    "                if 'buy_after_viewing' in temp_dict.keys():\n",
    "                    temp_dict['buy_after_viewing']=mergetwolists(temp_dict['buy_after_viewing'], mother_dict[j]['buy_after_viewing'])\n",
    "                else:\n",
    "                    temp_dict['buy_after_viewing']= mother_dict[j]['buy_after_viewing']\n",
    "            \n",
    "            if mother_dict[j]['categories'] != None:\n",
    "                if 'categories' in temp_dict.keys():\n",
    "                    temp_dict['categories']=mergetwolists(temp_dict['categories'], mother_dict[j]['categories'])\n",
    "                else:\n",
    "                    temp_dict['categories']= mother_dict[j]['categories']\n",
    "\n",
    "        output_dict[i].update(temp_dict)\n",
    "        \n",
    "    return output_dict\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_updateOutputDict= updateOutputDict(RAKE_output_dict,asin_mother_dict)\n",
    "# print testing_updateOutputDict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAKE_output_dict=updateOutputDict(RAKE_partial_output_dict,asin_mother_dict)\n",
    "TFIDF_output_dict= updateOutputDict(TFIDF_partial_output_dict, asin_mother_dict)\n",
    "# print RAKE_output_dict\n",
    "# print TFIDF_output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Health & Personal Care', 'Personal Care', 'Shaving & Hair Removal', 'Electric Shavers', 'Shaver Accessories', 'Health Care', 'Allergy, Sinus & Asthma', 'Sinus Medicine', 'Medical Supplies & Equipment', 'Home Tests', 'Drug Tests', 'Breathalyzers', 'Cold Sore & Fever Blister Treatments', 'Oral Hygiene', 'Breath Fresheners', 'Tongue Brushes, Scrapers & Cleaners', 'Foot Care', 'Foot Creams & Lotions', 'Diabetes Care', 'Sharps Containers', 'Test Strips', 'Urinalysis Strips', 'Eye Care', 'Eye Drops, Lubricants & Washes', 'Pain Relievers', 'Joint & Muscle Pain Relief', 'Medications', 'Massage & Relaxation', 'Electric Massagers', 'Denture Care', 'Adhesives', 'Household Supplies', 'Manual Shaving', 'Cleaning Tools', 'Brushes', 'Household Batteries', 'AA', 'Mopping']\n"
     ]
    }
   ],
   "source": [
    "print RAKE_output_dict[1]['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTopCategories(category_dict, number_of_categories_to_pick):\n",
    "    list_top_counts=[]\n",
    "    list_top_categories=[]\n",
    "    dict_top={}\n",
    "    number_of_dict_picked= number_of_categories_to_pick\n",
    "    for i in category_dict.keys():\n",
    "        if len(list_top_counts) < number_of_dict_picked:\n",
    "            list_top_counts.append(category_dict[i])\n",
    "            list_top_categories.append(i)\n",
    "        else:\n",
    "            min_value= min(list_top_counts)\n",
    "            if  min_value < category_dict[i]:\n",
    "                \n",
    "#                 print i +\" \" + str(category_dict[i])\n",
    "#                 print list_top_four_categories\n",
    "                list_top_counts[list_top_counts.index(min_value)]= category_dict[i]\n",
    "                for j in list_top_categories:\n",
    "                    if category_dict[j]== min_value:\n",
    "                        list_top_categories[list_top_categories.index(j)]= i\n",
    "                        break\n",
    "                        \n",
    "#     print(\"printing selected categories in helper function: \" + str(list_top_four_categories))                \n",
    "    for i in list_top_categories:\n",
    "        dict_top[i]= category_dict[i]\n",
    "#     print(\"printing selected categories in helper function: \" + str(dict_top_four))\n",
    "    return dict_top\n",
    "    \n",
    "#                 print \"category_dict\"+ str(category_dict)\n",
    "#                 print list_top_four_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputSummary(output_dict, mother_dict):\n",
    "    output_summary_dict={}\n",
    "    \n",
    "    for i in output_dict:\n",
    "        count_also_viewed=0\n",
    "        count_also_bought=0\n",
    "        count_bought_together=0\n",
    "        count_buy_after_viewing=0\n",
    "        asin_count_in_cluster=0\n",
    "        \n",
    "#         print output_dict[i]\n",
    "#         print output_dict[i]['also_viewed']\n",
    "\n",
    "        temp_dict={}\n",
    "        dict_category_distribution={}\n",
    "        for j in output_dict[i]['asins']:\n",
    "#             print j\n",
    "            asin_count_in_cluster+=1\n",
    "                \n",
    "            if j in output_dict[i]['also_viewed']:\n",
    "                count_also_viewed+=1\n",
    "                \n",
    "            if j in output_dict[i]['also_bought']:\n",
    "                count_also_bought+=1\n",
    "                \n",
    "            if j in output_dict[i]['bought_together']:\n",
    "                count_bought_together+=1\n",
    "                \n",
    "            if j in output_dict[i]['buy_after_viewing']:\n",
    "                count_buy_after_viewing+=1\n",
    "            \n",
    "            for k in mother_dict[j]['categories']:\n",
    "    #             print k\n",
    "    #             print dict_category_distribution.keys()\n",
    "                if k not in dict_category_distribution.keys():\n",
    "                    dict_category_distribution[k]=1\n",
    "                else:\n",
    "                    dict_category_distribution[k]+=1   \n",
    "#         print \"dict_category_distribution for cluster \" + str(i)+ \":\"+ str(dict_category_distribution)\n",
    "        top_categories=findTopCategories(dict_category_distribution,3)\n",
    "#         print \"top_four_categories for cluster \"+ str(i)+ \":\"+ str(top_categories)\n",
    "\n",
    "        temp_dict[\"also_viewed\"]= count_also_viewed\n",
    "        temp_dict[\"also_bought\"]= count_also_bought\n",
    "        temp_dict[\"bought_together\"]= count_bought_together\n",
    "        temp_dict[\"buy_after_viewing\"]= count_buy_after_viewing\n",
    "        temp_dict[\"asin_count_in_cluster\"]= asin_count_in_cluster\n",
    "        temp_dict[\"top_categories\"]= top_categories\n",
    "        temp_dict[\"count_related_products\"]= count_also_bought+count_also_viewed+count_bought_together+count_buy_after_viewing\n",
    "\n",
    "        output_summary_dict[i]=temp_dict\n",
    "    return output_summary_dict\n",
    "\n",
    "    #     print (\"cluster:\" + str(i)+ \" \"+ \"also_viewed\"+ str(count_also_viewed)+\" \"+ \"also_bought\"+\n",
    "    #            str(count_also_bought)+\" \"+\"bought_together\"+str(count_bought_together)+\" \"+\n",
    "    #            \"buy_after_viewing\"+ str(count_buy_after_viewing)+ \" \"+ \"asin count in cluster\"+ str(asin_count_in_cluster))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAKE_output_summary_dict= outputSummary(RAKE_output_dict, asin_mother_dict)\n",
    "TFIDF_output_summary_dict= outputSummary(TFIDF_output_dict, asin_mother_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['also_bought',\n",
       " 'also_viewed',\n",
       " 'bought_together',\n",
       " 'buy_after_viewing',\n",
       " 'asins',\n",
       " 'categories']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAKE_output_dict[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'asin_count_in_cluster': 4, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 4, 'Health Care': 3, 'Joint & Muscle Pain Relief': 2}, 'also_bought': 0, 'also_viewed': 0, 'bought_together': 0, 'count_related_products': 0}, 1: {'asin_count_in_cluster': 9, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 9, 'Household Supplies': 6, 'Personal Care': 3}, 'also_bought': 1, 'also_viewed': 0, 'bought_together': 1, 'count_related_products': 2}, 2: {'asin_count_in_cluster': 4, 'buy_after_viewing': 0, 'top_categories': {'Medical Supplies & Equipment': 2, 'Health & Personal Care': 4, 'Cushions': 2}, 'also_bought': 0, 'also_viewed': 0, 'bought_together': 0, 'count_related_products': 0}, 3: {'asin_count_in_cluster': 19, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 19, 'Household Supplies': 8, 'Personal Care': 8}, 'also_bought': 1, 'also_viewed': 2, 'bought_together': 1, 'count_related_products': 4}, 4: {'asin_count_in_cluster': 8, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 8, 'Health Care': 5, 'Pain Relievers': 4}, 'also_bought': 2, 'also_viewed': 3, 'bought_together': 0, 'count_related_products': 5}, 5: {'asin_count_in_cluster': 5, 'buy_after_viewing': 0, 'top_categories': {'Medical Supplies & Equipment': 2, 'Health & Personal Care': 5, 'AAA': 2}, 'also_bought': 1, 'also_viewed': 0, 'bought_together': 1, 'count_related_products': 2}, 6: {'asin_count_in_cluster': 23, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 23, 'Health Care': 8, 'Personal Care': 14}, 'also_bought': 2, 'also_viewed': 4, 'bought_together': 1, 'count_related_products': 7}, 7: {'asin_count_in_cluster': 8, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 8, 'Health Care': 4, 'Personal Care': 3}, 'also_bought': 4, 'also_viewed': 3, 'bought_together': 3, 'count_related_products': 10}, 8: {'asin_count_in_cluster': 12, 'buy_after_viewing': 0, 'top_categories': {'Medical Supplies & Equipment': 3, 'Health & Personal Care': 12, 'Health Care': 5}, 'also_bought': 0, 'also_viewed': 0, 'bought_together': 0, 'count_related_products': 0}, 9: {'asin_count_in_cluster': 8, 'buy_after_viewing': 0, 'top_categories': {'Shaving & Hair Removal': 3, 'Health & Personal Care': 8, 'Personal Care': 5}, 'also_bought': 1, 'also_viewed': 1, 'bought_together': 0, 'count_related_products': 2}}\n",
      "{0: {'asin_count_in_cluster': 6, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 6, 'Health Care': 4, 'Household Supplies': 3}, 'also_bought': 0, 'also_viewed': 0, 'bought_together': 0, 'count_related_products': 0}, 1: {'asin_count_in_cluster': 2, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 2, 'Health Care': 2, 'Thermometers': 2}, 'also_bought': 0, 'also_viewed': 0, 'bought_together': 0, 'count_related_products': 0}, 2: {'asin_count_in_cluster': 44, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 44, 'Health Care': 18, 'Personal Care': 19}, 'also_bought': 17, 'also_viewed': 16, 'bought_together': 8, 'count_related_products': 41}, 3: {'asin_count_in_cluster': 6, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 6, 'Dental Floss & Flossers': 3, 'Personal Care': 5}, 'also_bought': 0, 'also_viewed': 0, 'bought_together': 0, 'count_related_products': 0}, 4: {'asin_count_in_cluster': 1, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 1, 'AAA': 1, 'Household Supplies': 1}, 'also_bought': 1, 'also_viewed': 0, 'bought_together': 1, 'count_related_products': 2}, 5: {'asin_count_in_cluster': 1, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 1, 'Health Care': 1, 'Thermometers': 1}, 'also_bought': 0, 'also_viewed': 0, 'bought_together': 0, 'count_related_products': 0}, 6: {'asin_count_in_cluster': 13, 'buy_after_viewing': 0, 'top_categories': {'Shaving & Hair Removal': 5, 'Health & Personal Care': 13, 'Personal Care': 6}, 'also_bought': 0, 'also_viewed': 0, 'bought_together': 0, 'count_related_products': 0}, 7: {'asin_count_in_cluster': 15, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 15, 'Health Care': 5, 'Personal Care': 5}, 'also_bought': 0, 'also_viewed': 0, 'bought_together': 0, 'count_related_products': 0}, 8: {'asin_count_in_cluster': 8, 'buy_after_viewing': 0, 'top_categories': {'Medical Supplies & Equipment': 3, 'Health & Personal Care': 8, 'Personal Care': 4}, 'also_bought': 0, 'also_viewed': 0, 'bought_together': 0, 'count_related_products': 0}, 9: {'asin_count_in_cluster': 4, 'buy_after_viewing': 0, 'top_categories': {'Health & Personal Care': 4, 'Household Supplies': 3, 'Electric Shavers': 2}, 'also_bought': 1, 'also_viewed': 1, 'bought_together': 1, 'count_related_products': 3}}\n"
     ]
    }
   ],
   "source": [
    "print RAKE_output_summary_dict\n",
    "print TFIDF_output_summary_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dec 13_srishti_added this part to print error summary \n",
    "f = open(\"07_26_pm_Error_Analysis.txt\",\"w\")\n",
    "text=\" Number of ASINS= \" + str(number_of_reviews_for_clustering)\n",
    "f.write(text + '\\n')\n",
    "text= \" Number of clusters: \" + str(number_of_clusters) + \" K-Means Random state: \"+ str(kmeans_random_state)\n",
    "f.write(text + '\\n')\n",
    "\n",
    "text=\"number of ngrams used: \" + str(2)\n",
    "f.write(text + '\\n')\n",
    "\n",
    "text=\"number of keywords used: \" + str(max_word_per_review)\n",
    "f.write(text + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in RAKE_output_summary_dict.keys():\n",
    "    text = \"RAKE_Cluster Number: \" + str(i)+ str(RAKE_output_summary_dict[i])\n",
    "#     print text\n",
    "    f.write(text + '\\n')\n",
    "    \n",
    "for i in TFIDF_output_summary_dict.keys():\n",
    "    text = \"TFIDF_Cluster Number: \" + str(i)+ str(TFIDF_output_summary_dict[i])\n",
    "    f.write(text + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"07_26_pm_Output.txt\",\"w\")\n",
    "\n",
    "\n",
    "for i in RAKE_clusteredTitles.keys():\n",
    "    text = \"RAKE_Cluster Number: \" + str(i)+ str(RAKE_clusteredTitles[i])\n",
    "#     print text\n",
    "    f.write(text + '\\n')\n",
    "    \n",
    "for i in TFIDF_clusteredTitles.keys():\n",
    "    text = \"TFIDF_Cluster Number: \" + str(i)+ str(TFIDF_clusteredTitles[i])\n",
    "    f.write(text + '\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
