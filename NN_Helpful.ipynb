{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import io\n",
    "import re\n",
    "import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "from pprint import pprint\n",
    "import collections\n",
    "from scipy.stats import norm\n",
    "import gzip\n",
    "import math\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# 01_Helper functions\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_lower_bound(pos, n, confidence):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    z = norm.ppf(1-(1-confidence)/2)\n",
    "    phat = 1.0*pos/n\n",
    "    return (phat + z*z/(2*n) - z * math.sqrt((phat*(1-phat)+z*z/(4*n))/n))/(1+z*z/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dictionary whose keys are the full corpus of words in the training data set, and whose assigned values are all 0\n",
    "def generate_corpus(train_data_list):\n",
    "\tall_words = set()\n",
    "\tfeature_vec = {}\n",
    "\n",
    "\tfor k in range(0,len(train_data_list)):\n",
    "\t\twordList = re.sub(\"[^\\w]\", \" \",  train_data_list[k]).split() # Clean and split data\n",
    "\t\tfor words in wordList:\n",
    "\t\t\tall_words.add(words.lower())\n",
    "\n",
    "\treturn list(all_words)\n",
    "\t#feature_vec = {key: 0 for key in all_words}\n",
    "\n",
    "\t#for j in all_words:\n",
    "\t#\tfeature_vec[j] = 0\n",
    "\n",
    "\t#return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a string passed in, returns an ordered list of frequencies associated with each word in the corpus\n",
    "def return_dict_of_sentence(string_passed, corpus):\n",
    "\t#feature_vec = collections.defaultdict(int)\n",
    "\tfeature_vec = corpus\n",
    "\twordList = re.sub(\"[^\\w]\", \" \",  string_passed).split() # Clean and split data\n",
    "\tfor words in wordList:\n",
    "\t\tif words in corpus.keys():\n",
    "\t\t\tfeature_vec[words.lower()] += 1\n",
    "\n",
    "\t#return feature_vec\n",
    "\t#return np.array([feature_vec.keys(), feature_vec.values()])\n",
    "\treturn feature_vec.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with file\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# 02_Main function\n",
    "#####################\n",
    "\n",
    "reviews = []\n",
    "number_of_data_points_to_read = 15000 #Select number of data points to read\n",
    "counter= 1\n",
    "path= 'reviews_Health_and_Personal_Care_5.json.gz'\n",
    "\n",
    "for line in parse(path):\n",
    "    if counter <number_of_data_points_to_read:\n",
    "        reviews.append(line)\n",
    "        counter += 1\n",
    "    else:\n",
    "        break\n",
    "print \"done with file\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7247\n",
      "Read-in done\n"
     ]
    }
   ],
   "source": [
    "helpful_dict = collections.defaultdict(list)\n",
    "review_dict = collections.defaultdict(str)\n",
    "\n",
    "id = 1\n",
    "for i in reviews:\n",
    "    if i['helpful'][1] != 0:\n",
    "            helpful_dict[id] = i['helpful']\n",
    "            review_dict[id] = i['reviewText']\n",
    "            id += 1\n",
    "print id\n",
    "print \"Read-in done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into sets\n"
     ]
    }
   ],
   "source": [
    "##### Split into testing and training sets #####\n",
    "random.seed(42)\n",
    "\n",
    "train_set_x, test_set_x, train_set_y, test_set_y = train_test_split(review_dict.values(), [ci_lower_bound(i[0], i[1], 0.95) for i in helpful_dict.values()], test_size=0.2, random_state=None, shuffle= True) #split into train and test set\n",
    "\n",
    "print \"Split into sets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus generated\n"
     ]
    }
   ],
   "source": [
    "##### Create corpus, convert reviews to feature vectors #####\n",
    "\n",
    "if False: # Change to False once corpus generated\n",
    "    corpus = generate_corpus(train_set_x)\n",
    "    with io.open('hpc_corpus.csv', 'wb') as myfile:\n",
    "        wr = csv.writer(myfile)\n",
    "        for i in corpus:\n",
    "            wr.writerow([i])\n",
    "else:\n",
    "    with io.open('hpc_corpus.csv', 'rb') as csvfile:\n",
    "        data = csv.reader(csvfile)\n",
    "        corpus = list(data)\n",
    "        corpus = [corpus[i][0] for i in range(len(corpus))]\n",
    "\n",
    "corpus = {c: 0 for c in corpus}\n",
    "print \"Corpus generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the dictionary of each example\n",
    "features = []\n",
    "for xi in range(0,len(train_set_x)):\n",
    "    #### return_dict_of_sentence is a function that takes a sentence, and the corpus dictionary as input and returns an updated dictionary with count of present words updated\n",
    "    features.append(return_dict_of_sentence(train_set_x[xi], corpus))\n",
    "\n",
    "print len(features)\n",
    "print len(train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run MLP Regression on training set\n",
    "\n",
    "clf = MLPRegressor()\n",
    "clf.fit(X = features, y = train_set_y)\n",
    "score = clf.score(X = features, y = train_set_y)\n",
    "train_predict = clf.predict(features)\n",
    "\n",
    "# Calculate the proportion correctly classified for training set\n",
    "print \"TRAIN DATA SET\"\n",
    "print \"Average predicted score\"\n",
    "print mean(train_predict)\n",
    "print \"Actual score range\"\n",
    "print (min(train_set_y) + \"-\" + min(train_set_y))\n",
    "print \"Training error\"\n",
    "meanSquaredError=mean_squared_error(train_set_y, train_predict)\n",
    "print(\"MSE:\", meanSquaredError)\n",
    "rootMeanSquaredError = math.sqrt(meanSquaredError)\n",
    "print(\"RMSE:\", rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# 03_Running the test data set through feature vector calculated above\n",
    "###################\n",
    "\n",
    "##### Extract review and rating #####\n",
    "\n",
    "### Create the dictionary of each example\n",
    "test_features = []\n",
    "for xi in range(0,len(test_set_x)):\n",
    "    #### return_dict_of_sentence is a function that takes a sentence, and the corpus dictionary as input and returns an updated dictionary with count of present words updated\n",
    "    test_features.append(return_dict_of_sentence(test_set_x[xi], corpus))\n",
    "\n",
    "#predictions = logit.predict(test_features)\n",
    "predictions = clf.predict(test_features)\n",
    "\n",
    "\n",
    "# Calculate the proportion correctly classified for testing set\n",
    "print \"TEST DATA SET\"\n",
    "print \"Average predicted score\"\n",
    "print mean(predictions)\n",
    "print \"Testing error\"\n",
    "meanSquaredError=mean_squared_error(test_set_y, predictions)\n",
    "print(\"MSE:\", meanSquaredError)\n",
    "rootMeanSquaredError = math.sqrt(meanSquaredError)\n",
    "print(\"RMSE:\", rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# 04_Predict usefulness score of new review\n",
    "###################\n",
    "\n",
    "input_set_x = [\"It was great!\"]\n",
    "\n",
    "### Create the dictionary of each example\n",
    "input_features = []\n",
    "for xi in range(0,len(input_set_x)):\n",
    "    #### return_dict_of_sentence is a function that takes a sentence, and the corpus dictionary as input and returns an updated dictionary with count of present words updated\n",
    "    input_features.append(return_dict_of_sentence(input_set_x[xi], corpus))\n",
    "\n",
    "input_prediction = clf.predict(input_features)\n",
    "\n",
    "print input_set_x\n",
    "print input_prediction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
